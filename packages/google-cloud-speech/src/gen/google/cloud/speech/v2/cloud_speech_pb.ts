// Copyright 2023 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// @generated by protoc-gen-es v1.2.0 with parameter "target=ts"
// @generated from file google/cloud/speech/v2/cloud_speech.proto (package google.cloud.speech.v2, syntax proto3)
/* eslint-disable */
// @ts-nocheck

import type { BinaryReadOptions, FieldList, JsonReadOptions, JsonValue, PartialMessage, PlainMessage } from "@bufbuild/protobuf";
import { Duration, FieldMask, Message, proto3, Timestamp } from "@bufbuild/protobuf";
import { Status } from "../../../rpc/status_pb.js";

/**
 * Request message for the
 * [CreateRecognizer][google.cloud.speech.v2.Speech.CreateRecognizer] method.
 *
 * @generated from message google.cloud.speech.v2.CreateRecognizerRequest
 */
export class CreateRecognizerRequest extends Message<CreateRecognizerRequest> {
  /**
   * Required. The Recognizer to create.
   *
   * @generated from field: google.cloud.speech.v2.Recognizer recognizer = 1;
   */
  recognizer?: Recognizer;

  /**
   * If set, validate the request and preview the Recognizer, but do not
   * actually create it.
   *
   * @generated from field: bool validate_only = 2;
   */
  validateOnly = false;

  /**
   * The ID to use for the Recognizer, which will become the final component of
   * the Recognizer's resource name.
   *
   * This value should be 4-63 characters, and valid characters
   * are /[a-z][0-9]-/.
   *
   * @generated from field: string recognizer_id = 3;
   */
  recognizerId = "";

  /**
   * Required. The project and location where this Recognizer will be created.
   * The expected format is `projects/{project}/locations/{location}`.
   *
   * @generated from field: string parent = 4;
   */
  parent = "";

  constructor(data?: PartialMessage<CreateRecognizerRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.speech.v2.CreateRecognizerRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "recognizer", kind: "message", T: Recognizer },
    { no: 2, name: "validate_only", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
    { no: 3, name: "recognizer_id", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 4, name: "parent", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): CreateRecognizerRequest {
    return new CreateRecognizerRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): CreateRecognizerRequest {
    return new CreateRecognizerRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): CreateRecognizerRequest {
    return new CreateRecognizerRequest().fromJsonString(jsonString, options);
  }

  static equals(a: CreateRecognizerRequest | PlainMessage<CreateRecognizerRequest> | undefined, b: CreateRecognizerRequest | PlainMessage<CreateRecognizerRequest> | undefined): boolean {
    return proto3.util.equals(CreateRecognizerRequest, a, b);
  }
}

/**
 * Represents the metadata of a long-running operation.
 *
 * @generated from message google.cloud.speech.v2.OperationMetadata
 */
export class OperationMetadata extends Message<OperationMetadata> {
  /**
   * The time the operation was created.
   *
   * @generated from field: google.protobuf.Timestamp create_time = 1;
   */
  createTime?: Timestamp;

  /**
   * The time the operation was last updated.
   *
   * @generated from field: google.protobuf.Timestamp update_time = 2;
   */
  updateTime?: Timestamp;

  /**
   * The resource path for the target of the operation.
   *
   * @generated from field: string resource = 3;
   */
  resource = "";

  /**
   * The method that triggered the operation.
   *
   * @generated from field: string method = 4;
   */
  method = "";

  /**
   * The [KMS key
   * name](https://cloud.google.com/kms/docs/resource-hierarchy#keys) with which
   * the content of the Operation is encrypted. The expected format is
   * `projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}`.
   *
   * @generated from field: string kms_key_name = 6;
   */
  kmsKeyName = "";

  /**
   * The [KMS key version
   * name](https://cloud.google.com/kms/docs/resource-hierarchy#key_versions)
   * with which content of the Operation is encrypted. The expected format is
   * `projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}/cryptoKeyVersions/{crypto_key_version}`.
   *
   * @generated from field: string kms_key_version_name = 7;
   */
  kmsKeyVersionName = "";

  /**
   * The request that spawned the Operation.
   *
   * @generated from oneof google.cloud.speech.v2.OperationMetadata.request
   */
  request: {
    /**
     * The BatchRecognizeRequest that spawned the Operation.
     *
     * @generated from field: google.cloud.speech.v2.BatchRecognizeRequest batch_recognize_request = 8;
     */
    value: BatchRecognizeRequest;
    case: "batchRecognizeRequest";
  } | {
    /**
     * The CreateRecognizerRequest that spawned the Operation.
     *
     * @generated from field: google.cloud.speech.v2.CreateRecognizerRequest create_recognizer_request = 9;
     */
    value: CreateRecognizerRequest;
    case: "createRecognizerRequest";
  } | {
    /**
     * The UpdateRecognizerRequest that spawned the Operation.
     *
     * @generated from field: google.cloud.speech.v2.UpdateRecognizerRequest update_recognizer_request = 10;
     */
    value: UpdateRecognizerRequest;
    case: "updateRecognizerRequest";
  } | {
    /**
     * The DeleteRecognizerRequest that spawned the Operation.
     *
     * @generated from field: google.cloud.speech.v2.DeleteRecognizerRequest delete_recognizer_request = 11;
     */
    value: DeleteRecognizerRequest;
    case: "deleteRecognizerRequest";
  } | {
    /**
     * The UndeleteRecognizerRequest that spawned the Operation.
     *
     * @generated from field: google.cloud.speech.v2.UndeleteRecognizerRequest undelete_recognizer_request = 12;
     */
    value: UndeleteRecognizerRequest;
    case: "undeleteRecognizerRequest";
  } | {
    /**
     * The CreateCustomClassRequest that spawned the Operation.
     *
     * @generated from field: google.cloud.speech.v2.CreateCustomClassRequest create_custom_class_request = 13;
     */
    value: CreateCustomClassRequest;
    case: "createCustomClassRequest";
  } | {
    /**
     * The UpdateCustomClassRequest that spawned the Operation.
     *
     * @generated from field: google.cloud.speech.v2.UpdateCustomClassRequest update_custom_class_request = 14;
     */
    value: UpdateCustomClassRequest;
    case: "updateCustomClassRequest";
  } | {
    /**
     * The DeleteCustomClassRequest that spawned the Operation.
     *
     * @generated from field: google.cloud.speech.v2.DeleteCustomClassRequest delete_custom_class_request = 15;
     */
    value: DeleteCustomClassRequest;
    case: "deleteCustomClassRequest";
  } | {
    /**
     * The UndeleteCustomClassRequest that spawned the Operation.
     *
     * @generated from field: google.cloud.speech.v2.UndeleteCustomClassRequest undelete_custom_class_request = 16;
     */
    value: UndeleteCustomClassRequest;
    case: "undeleteCustomClassRequest";
  } | {
    /**
     * The CreatePhraseSetRequest that spawned the Operation.
     *
     * @generated from field: google.cloud.speech.v2.CreatePhraseSetRequest create_phrase_set_request = 17;
     */
    value: CreatePhraseSetRequest;
    case: "createPhraseSetRequest";
  } | {
    /**
     * The UpdatePhraseSetRequest that spawned the Operation.
     *
     * @generated from field: google.cloud.speech.v2.UpdatePhraseSetRequest update_phrase_set_request = 18;
     */
    value: UpdatePhraseSetRequest;
    case: "updatePhraseSetRequest";
  } | {
    /**
     * The DeletePhraseSetRequest that spawned the Operation.
     *
     * @generated from field: google.cloud.speech.v2.DeletePhraseSetRequest delete_phrase_set_request = 19;
     */
    value: DeletePhraseSetRequest;
    case: "deletePhraseSetRequest";
  } | {
    /**
     * The UndeletePhraseSetRequest that spawned the Operation.
     *
     * @generated from field: google.cloud.speech.v2.UndeletePhraseSetRequest undelete_phrase_set_request = 20;
     */
    value: UndeletePhraseSetRequest;
    case: "undeletePhraseSetRequest";
  } | {
    /**
     * The UpdateConfigRequest that spawned the Operation.
     *
     * @generated from field: google.cloud.speech.v2.UpdateConfigRequest update_config_request = 21 [deprecated = true];
     * @deprecated
     */
    value: UpdateConfigRequest;
    case: "updateConfigRequest";
  } | { case: undefined; value?: undefined } = { case: undefined };

  /**
   * The percent progress of the Operation. Values can range from 0-100. If the
   * value is 100, then the operation is finished.
   *
   * @generated from field: int32 progress_percent = 22;
   */
  progressPercent = 0;

  /**
   * Specific metadata per RPC.
   *
   * @generated from oneof google.cloud.speech.v2.OperationMetadata.metadata
   */
  metadata: {
    /**
     * Metadata specific to the BatchRecognize method.
     *
     * @generated from field: google.cloud.speech.v2.BatchRecognizeMetadata batch_recognize_metadata = 23;
     */
    value: BatchRecognizeMetadata;
    case: "batchRecognizeMetadata";
  } | { case: undefined; value?: undefined } = { case: undefined };

  constructor(data?: PartialMessage<OperationMetadata>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.speech.v2.OperationMetadata";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "create_time", kind: "message", T: Timestamp },
    { no: 2, name: "update_time", kind: "message", T: Timestamp },
    { no: 3, name: "resource", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 4, name: "method", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 6, name: "kms_key_name", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 7, name: "kms_key_version_name", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 8, name: "batch_recognize_request", kind: "message", T: BatchRecognizeRequest, oneof: "request" },
    { no: 9, name: "create_recognizer_request", kind: "message", T: CreateRecognizerRequest, oneof: "request" },
    { no: 10, name: "update_recognizer_request", kind: "message", T: UpdateRecognizerRequest, oneof: "request" },
    { no: 11, name: "delete_recognizer_request", kind: "message", T: DeleteRecognizerRequest, oneof: "request" },
    { no: 12, name: "undelete_recognizer_request", kind: "message", T: UndeleteRecognizerRequest, oneof: "request" },
    { no: 13, name: "create_custom_class_request", kind: "message", T: CreateCustomClassRequest, oneof: "request" },
    { no: 14, name: "update_custom_class_request", kind: "message", T: UpdateCustomClassRequest, oneof: "request" },
    { no: 15, name: "delete_custom_class_request", kind: "message", T: DeleteCustomClassRequest, oneof: "request" },
    { no: 16, name: "undelete_custom_class_request", kind: "message", T: UndeleteCustomClassRequest, oneof: "request" },
    { no: 17, name: "create_phrase_set_request", kind: "message", T: CreatePhraseSetRequest, oneof: "request" },
    { no: 18, name: "update_phrase_set_request", kind: "message", T: UpdatePhraseSetRequest, oneof: "request" },
    { no: 19, name: "delete_phrase_set_request", kind: "message", T: DeletePhraseSetRequest, oneof: "request" },
    { no: 20, name: "undelete_phrase_set_request", kind: "message", T: UndeletePhraseSetRequest, oneof: "request" },
    { no: 21, name: "update_config_request", kind: "message", T: UpdateConfigRequest, oneof: "request" },
    { no: 22, name: "progress_percent", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 23, name: "batch_recognize_metadata", kind: "message", T: BatchRecognizeMetadata, oneof: "metadata" },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): OperationMetadata {
    return new OperationMetadata().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): OperationMetadata {
    return new OperationMetadata().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): OperationMetadata {
    return new OperationMetadata().fromJsonString(jsonString, options);
  }

  static equals(a: OperationMetadata | PlainMessage<OperationMetadata> | undefined, b: OperationMetadata | PlainMessage<OperationMetadata> | undefined): boolean {
    return proto3.util.equals(OperationMetadata, a, b);
  }
}

/**
 * Request message for the
 * [ListRecognizers][google.cloud.speech.v2.Speech.ListRecognizers] method.
 *
 * @generated from message google.cloud.speech.v2.ListRecognizersRequest
 */
export class ListRecognizersRequest extends Message<ListRecognizersRequest> {
  /**
   * Required. The project and location of Recognizers to list. The expected
   * format is `projects/{project}/locations/{location}`.
   *
   * @generated from field: string parent = 1;
   */
  parent = "";

  /**
   * The maximum number of Recognizers to return. The service may return fewer
   * than this value. If unspecified, at most 20 Recognizers will be returned.
   * The maximum value is 20; values above 20 will be coerced to 20.
   *
   * @generated from field: int32 page_size = 2;
   */
  pageSize = 0;

  /**
   * A page token, received from a previous
   * [ListRecognizers][google.cloud.speech.v2.Speech.ListRecognizers] call.
   * Provide this to retrieve the subsequent page.
   *
   * When paginating, all other parameters provided to
   * [ListRecognizers][google.cloud.speech.v2.Speech.ListRecognizers] must match
   * the call that provided the page token.
   *
   * @generated from field: string page_token = 3;
   */
  pageToken = "";

  /**
   * Whether, or not, to show resources that have been deleted.
   *
   * @generated from field: bool show_deleted = 4;
   */
  showDeleted = false;

  constructor(data?: PartialMessage<ListRecognizersRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.speech.v2.ListRecognizersRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "parent", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "page_size", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 3, name: "page_token", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 4, name: "show_deleted", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ListRecognizersRequest {
    return new ListRecognizersRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ListRecognizersRequest {
    return new ListRecognizersRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ListRecognizersRequest {
    return new ListRecognizersRequest().fromJsonString(jsonString, options);
  }

  static equals(a: ListRecognizersRequest | PlainMessage<ListRecognizersRequest> | undefined, b: ListRecognizersRequest | PlainMessage<ListRecognizersRequest> | undefined): boolean {
    return proto3.util.equals(ListRecognizersRequest, a, b);
  }
}

/**
 * Response message for the
 * [ListRecognizers][google.cloud.speech.v2.Speech.ListRecognizers] method.
 *
 * @generated from message google.cloud.speech.v2.ListRecognizersResponse
 */
export class ListRecognizersResponse extends Message<ListRecognizersResponse> {
  /**
   * The list of requested Recognizers.
   *
   * @generated from field: repeated google.cloud.speech.v2.Recognizer recognizers = 1;
   */
  recognizers: Recognizer[] = [];

  /**
   * A token, which can be sent as
   * [page_token][google.cloud.speech.v2.ListRecognizersRequest.page_token] to
   * retrieve the next page. If this field is omitted, there are no subsequent
   * pages. This token expires after 72 hours.
   *
   * @generated from field: string next_page_token = 2;
   */
  nextPageToken = "";

  constructor(data?: PartialMessage<ListRecognizersResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.speech.v2.ListRecognizersResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "recognizers", kind: "message", T: Recognizer, repeated: true },
    { no: 2, name: "next_page_token", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ListRecognizersResponse {
    return new ListRecognizersResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ListRecognizersResponse {
    return new ListRecognizersResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ListRecognizersResponse {
    return new ListRecognizersResponse().fromJsonString(jsonString, options);
  }

  static equals(a: ListRecognizersResponse | PlainMessage<ListRecognizersResponse> | undefined, b: ListRecognizersResponse | PlainMessage<ListRecognizersResponse> | undefined): boolean {
    return proto3.util.equals(ListRecognizersResponse, a, b);
  }
}

/**
 * Request message for the
 * [GetRecognizer][google.cloud.speech.v2.Speech.GetRecognizer] method.
 *
 * @generated from message google.cloud.speech.v2.GetRecognizerRequest
 */
export class GetRecognizerRequest extends Message<GetRecognizerRequest> {
  /**
   * Required. The name of the Recognizer to retrieve. The expected format is
   * `projects/{project}/locations/{location}/recognizers/{recognizer}`.
   *
   * @generated from field: string name = 1;
   */
  name = "";

  constructor(data?: PartialMessage<GetRecognizerRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.speech.v2.GetRecognizerRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "name", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): GetRecognizerRequest {
    return new GetRecognizerRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): GetRecognizerRequest {
    return new GetRecognizerRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): GetRecognizerRequest {
    return new GetRecognizerRequest().fromJsonString(jsonString, options);
  }

  static equals(a: GetRecognizerRequest | PlainMessage<GetRecognizerRequest> | undefined, b: GetRecognizerRequest | PlainMessage<GetRecognizerRequest> | undefined): boolean {
    return proto3.util.equals(GetRecognizerRequest, a, b);
  }
}

/**
 * Request message for the
 * [UpdateRecognizer][google.cloud.speech.v2.Speech.UpdateRecognizer] method.
 *
 * @generated from message google.cloud.speech.v2.UpdateRecognizerRequest
 */
export class UpdateRecognizerRequest extends Message<UpdateRecognizerRequest> {
  /**
   * Required. The Recognizer to update.
   *
   * The Recognizer's `name` field is used to identify the Recognizer to update.
   * Format: `projects/{project}/locations/{location}/recognizers/{recognizer}`.
   *
   * @generated from field: google.cloud.speech.v2.Recognizer recognizer = 1;
   */
  recognizer?: Recognizer;

  /**
   * The list of fields to update. If empty, all non-default valued fields are
   * considered for update. Use `*` to update the entire Recognizer resource.
   *
   * @generated from field: google.protobuf.FieldMask update_mask = 2;
   */
  updateMask?: FieldMask;

  /**
   * If set, validate the request and preview the updated Recognizer, but do not
   * actually update it.
   *
   * @generated from field: bool validate_only = 4;
   */
  validateOnly = false;

  constructor(data?: PartialMessage<UpdateRecognizerRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.speech.v2.UpdateRecognizerRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "recognizer", kind: "message", T: Recognizer },
    { no: 2, name: "update_mask", kind: "message", T: FieldMask },
    { no: 4, name: "validate_only", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): UpdateRecognizerRequest {
    return new UpdateRecognizerRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): UpdateRecognizerRequest {
    return new UpdateRecognizerRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): UpdateRecognizerRequest {
    return new UpdateRecognizerRequest().fromJsonString(jsonString, options);
  }

  static equals(a: UpdateRecognizerRequest | PlainMessage<UpdateRecognizerRequest> | undefined, b: UpdateRecognizerRequest | PlainMessage<UpdateRecognizerRequest> | undefined): boolean {
    return proto3.util.equals(UpdateRecognizerRequest, a, b);
  }
}

/**
 * Request message for the
 * [DeleteRecognizer][google.cloud.speech.v2.Speech.DeleteRecognizer] method.
 *
 * @generated from message google.cloud.speech.v2.DeleteRecognizerRequest
 */
export class DeleteRecognizerRequest extends Message<DeleteRecognizerRequest> {
  /**
   * Required. The name of the Recognizer to delete.
   * Format: `projects/{project}/locations/{location}/recognizers/{recognizer}`
   *
   * @generated from field: string name = 1;
   */
  name = "";

  /**
   * If set, validate the request and preview the deleted Recognizer, but do not
   * actually delete it.
   *
   * @generated from field: bool validate_only = 2;
   */
  validateOnly = false;

  /**
   * If set to true, and the Recognizer is not found, the request will succeed
   * and  be a no-op (no Operation is recorded in this case).
   *
   * @generated from field: bool allow_missing = 4;
   */
  allowMissing = false;

  /**
   * This checksum is computed by the server based on the value of other
   * fields. This may be sent on update, undelete, and delete requests to ensure
   * the client has an up-to-date value before proceeding.
   *
   * @generated from field: string etag = 3;
   */
  etag = "";

  constructor(data?: PartialMessage<DeleteRecognizerRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.speech.v2.DeleteRecognizerRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "name", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "validate_only", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
    { no: 4, name: "allow_missing", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
    { no: 3, name: "etag", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): DeleteRecognizerRequest {
    return new DeleteRecognizerRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): DeleteRecognizerRequest {
    return new DeleteRecognizerRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): DeleteRecognizerRequest {
    return new DeleteRecognizerRequest().fromJsonString(jsonString, options);
  }

  static equals(a: DeleteRecognizerRequest | PlainMessage<DeleteRecognizerRequest> | undefined, b: DeleteRecognizerRequest | PlainMessage<DeleteRecognizerRequest> | undefined): boolean {
    return proto3.util.equals(DeleteRecognizerRequest, a, b);
  }
}

/**
 * Request message for the
 * [UndeleteRecognizer][google.cloud.speech.v2.Speech.UndeleteRecognizer]
 * method.
 *
 * @generated from message google.cloud.speech.v2.UndeleteRecognizerRequest
 */
export class UndeleteRecognizerRequest extends Message<UndeleteRecognizerRequest> {
  /**
   * Required. The name of the Recognizer to undelete.
   * Format: `projects/{project}/locations/{location}/recognizers/{recognizer}`
   *
   * @generated from field: string name = 1;
   */
  name = "";

  /**
   * If set, validate the request and preview the undeleted Recognizer, but do
   * not actually undelete it.
   *
   * @generated from field: bool validate_only = 3;
   */
  validateOnly = false;

  /**
   * This checksum is computed by the server based on the value of other
   * fields. This may be sent on update, undelete, and delete requests to ensure
   * the client has an up-to-date value before proceeding.
   *
   * @generated from field: string etag = 4;
   */
  etag = "";

  constructor(data?: PartialMessage<UndeleteRecognizerRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.speech.v2.UndeleteRecognizerRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "name", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 3, name: "validate_only", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
    { no: 4, name: "etag", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): UndeleteRecognizerRequest {
    return new UndeleteRecognizerRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): UndeleteRecognizerRequest {
    return new UndeleteRecognizerRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): UndeleteRecognizerRequest {
    return new UndeleteRecognizerRequest().fromJsonString(jsonString, options);
  }

  static equals(a: UndeleteRecognizerRequest | PlainMessage<UndeleteRecognizerRequest> | undefined, b: UndeleteRecognizerRequest | PlainMessage<UndeleteRecognizerRequest> | undefined): boolean {
    return proto3.util.equals(UndeleteRecognizerRequest, a, b);
  }
}

/**
 * A Recognizer message. Stores recognition configuration and metadata.
 *
 * @generated from message google.cloud.speech.v2.Recognizer
 */
export class Recognizer extends Message<Recognizer> {
  /**
   * Output only. The resource name of the Recognizer.
   * Format: `projects/{project}/locations/{location}/recognizers/{recognizer}`.
   *
   * @generated from field: string name = 1;
   */
  name = "";

  /**
   * Output only. System-assigned unique identifier for the Recognizer.
   *
   * @generated from field: string uid = 2;
   */
  uid = "";

  /**
   * User-settable, human-readable name for the Recognizer. Must be 63
   * characters or less.
   *
   * @generated from field: string display_name = 3;
   */
  displayName = "";

  /**
   * Required. Which model to use for recognition requests. Select the model
   * best suited to your domain to get best results.
   *
   * Supported models:
   *
   * - `latest_long`
   *
   *   Best for long form content like media or conversation.
   *
   * - `latest_short`
   *
   *   Best for short form content like commands or single shot directed speech.
   *   When using this model, the service will stop transcribing audio after the
   *   first utterance is detected and completed.
   *
   *   When using this model,
   *   [SEPARATE_RECOGNITION_PER_CHANNEL][google.cloud.speech.v2.RecognitionFeatures.MultiChannelMode.SEPARATE_RECOGNITION_PER_CHANNEL]
   *   is not supported; multi-channel audio is accepted, but only the first
   *   channel will be processed and transcribed.
   *
   * - `telephony`
   *
   *   Best for audio that originated from a phone call (typically recorded at
   *   an 8khz sampling rate).
   *
   * - `medical_conversation`
   *
   *   For conversations between a medical provider—for example, a doctor or
   *   nurse—and a patient. Use this model when both a provider and a patient
   *   are speaking. Words uttered by each speaker are automatically detected
   *   and labeled in the returned transcript.
   *
   *   For supported features please see [medical models
   *   documentation](https://cloud.google.com/speech-to-text/docs/medical-models).
   *
   * - `medical_dictation`
   *
   *   For dictated notes spoken by a single medical provider—for example, a
   *   doctor dictating notes about a patient's blood test results.
   *
   *   For supported features please see [medical models
   *   documentation](https://cloud.google.com/speech-to-text/docs/medical-models).
   *
   * - `usm`
   *
   *   The next generation of Speech-to-Text models from Google.
   *
   * @generated from field: string model = 4;
   */
  model = "";

  /**
   * Required. The language of the supplied audio as a
   * [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag.
   *
   * Supported languages for each model are listed at:
   * https://cloud.google.com/speech-to-text/docs/languages
   *
   * If additional languages are provided, recognition result will contain
   * recognition in the most likely language detected. The recognition result
   * will include the language tag of the language detected in the audio.
   * When you create or update a Recognizer, these values are
   * stored in normalized BCP-47 form. For example, "en-us" is stored as
   * "en-US".
   *
   * @generated from field: repeated string language_codes = 17;
   */
  languageCodes: string[] = [];

  /**
   * Default configuration to use for requests with this Recognizer.
   * This can be overwritten by inline configuration in the
   * [RecognizeRequest.config][google.cloud.speech.v2.RecognizeRequest.config]
   * field.
   *
   * @generated from field: google.cloud.speech.v2.RecognitionConfig default_recognition_config = 6;
   */
  defaultRecognitionConfig?: RecognitionConfig;

  /**
   * Allows users to store small amounts of arbitrary data.
   * Both the key and the value must be 63 characters or less each.
   * At most 100 annotations.
   *
   * @generated from field: map<string, string> annotations = 7;
   */
  annotations: { [key: string]: string } = {};

  /**
   * Output only. The Recognizer lifecycle state.
   *
   * @generated from field: google.cloud.speech.v2.Recognizer.State state = 8;
   */
  state = Recognizer_State.STATE_UNSPECIFIED;

  /**
   * Output only. Creation time.
   *
   * @generated from field: google.protobuf.Timestamp create_time = 9;
   */
  createTime?: Timestamp;

  /**
   * Output only. The most recent time this Recognizer was modified.
   *
   * @generated from field: google.protobuf.Timestamp update_time = 10;
   */
  updateTime?: Timestamp;

  /**
   * Output only. The time at which this Recognizer was requested for deletion.
   *
   * @generated from field: google.protobuf.Timestamp delete_time = 11;
   */
  deleteTime?: Timestamp;

  /**
   * Output only. The time at which this Recognizer will be purged.
   *
   * @generated from field: google.protobuf.Timestamp expire_time = 14;
   */
  expireTime?: Timestamp;

  /**
   * Output only. This checksum is computed by the server based on the value of
   * other fields. This may be sent on update, undelete, and delete requests to
   * ensure the client has an up-to-date value before proceeding.
   *
   * @generated from field: string etag = 12;
   */
  etag = "";

  /**
   * Output only. Whether or not this Recognizer is in the process of being
   * updated.
   *
   * @generated from field: bool reconciling = 13;
   */
  reconciling = false;

  /**
   * Output only. The [KMS key
   * name](https://cloud.google.com/kms/docs/resource-hierarchy#keys) with which
   * the Recognizer is encrypted. The expected format is
   * `projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}`.
   *
   * @generated from field: string kms_key_name = 15;
   */
  kmsKeyName = "";

  /**
   * Output only. The [KMS key version
   * name](https://cloud.google.com/kms/docs/resource-hierarchy#key_versions)
   * with which the Recognizer is encrypted. The expected format is
   * `projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}/cryptoKeyVersions/{crypto_key_version}`.
   *
   * @generated from field: string kms_key_version_name = 16;
   */
  kmsKeyVersionName = "";

  constructor(data?: PartialMessage<Recognizer>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.speech.v2.Recognizer";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "name", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "uid", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 3, name: "display_name", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 4, name: "model", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 17, name: "language_codes", kind: "scalar", T: 9 /* ScalarType.STRING */, repeated: true },
    { no: 6, name: "default_recognition_config", kind: "message", T: RecognitionConfig },
    { no: 7, name: "annotations", kind: "map", K: 9 /* ScalarType.STRING */, V: {kind: "scalar", T: 9 /* ScalarType.STRING */} },
    { no: 8, name: "state", kind: "enum", T: proto3.getEnumType(Recognizer_State) },
    { no: 9, name: "create_time", kind: "message", T: Timestamp },
    { no: 10, name: "update_time", kind: "message", T: Timestamp },
    { no: 11, name: "delete_time", kind: "message", T: Timestamp },
    { no: 14, name: "expire_time", kind: "message", T: Timestamp },
    { no: 12, name: "etag", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 13, name: "reconciling", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
    { no: 15, name: "kms_key_name", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 16, name: "kms_key_version_name", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): Recognizer {
    return new Recognizer().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): Recognizer {
    return new Recognizer().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): Recognizer {
    return new Recognizer().fromJsonString(jsonString, options);
  }

  static equals(a: Recognizer | PlainMessage<Recognizer> | undefined, b: Recognizer | PlainMessage<Recognizer> | undefined): boolean {
    return proto3.util.equals(Recognizer, a, b);
  }
}

/**
 * Set of states that define the lifecycle of a Recognizer.
 *
 * @generated from enum google.cloud.speech.v2.Recognizer.State
 */
export enum Recognizer_State {
  /**
   * The default value. This value is used if the state is omitted.
   *
   * @generated from enum value: STATE_UNSPECIFIED = 0;
   */
  STATE_UNSPECIFIED = 0,

  /**
   * The Recognizer is active and ready for use.
   *
   * @generated from enum value: ACTIVE = 2;
   */
  ACTIVE = 2,

  /**
   * This Recognizer has been deleted.
   *
   * @generated from enum value: DELETED = 4;
   */
  DELETED = 4,
}
// Retrieve enum metadata with: proto3.getEnumType(Recognizer_State)
proto3.util.setEnumType(Recognizer_State, "google.cloud.speech.v2.Recognizer.State", [
  { no: 0, name: "STATE_UNSPECIFIED" },
  { no: 2, name: "ACTIVE" },
  { no: 4, name: "DELETED" },
]);

/**
 * Automatically detected decoding parameters.
 * Supported for the following encodings:
 *
 * * WAV_LINEAR16: 16-bit signed little-endian PCM samples in a WAV container.
 *
 * * WAV_MULAW: 8-bit companded mulaw samples in a WAV container.
 *
 * * WAV_ALAW: 8-bit companded alaw samples in a WAV container.
 *
 * * RFC4867_5_AMR: AMR frames with an rfc4867.5 header.
 *
 * * RFC4867_5_AMRWB: AMR-WB frames with an rfc4867.5 header.
 *
 * * FLAC: FLAC frames in the "native FLAC" container format.
 *
 * * MP3: MPEG audio frames with optional (ignored) ID3 metadata.
 *
 * * OGG_OPUS: Opus audio frames in an Ogg container.
 *
 * * WEBM_OPUS: Opus audio frames in a WebM container.
 *
 * @generated from message google.cloud.speech.v2.AutoDetectDecodingConfig
 */
export class AutoDetectDecodingConfig extends Message<AutoDetectDecodingConfig> {
  constructor(data?: PartialMessage<AutoDetectDecodingConfig>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.speech.v2.AutoDetectDecodingConfig";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): AutoDetectDecodingConfig {
    return new AutoDetectDecodingConfig().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): AutoDetectDecodingConfig {
    return new AutoDetectDecodingConfig().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): AutoDetectDecodingConfig {
    return new AutoDetectDecodingConfig().fromJsonString(jsonString, options);
  }

  static equals(a: AutoDetectDecodingConfig | PlainMessage<AutoDetectDecodingConfig> | undefined, b: AutoDetectDecodingConfig | PlainMessage<AutoDetectDecodingConfig> | undefined): boolean {
    return proto3.util.equals(AutoDetectDecodingConfig, a, b);
  }
}

/**
 * Explicitly specified decoding parameters.
 *
 * @generated from message google.cloud.speech.v2.ExplicitDecodingConfig
 */
export class ExplicitDecodingConfig extends Message<ExplicitDecodingConfig> {
  /**
   * Required. Encoding of the audio data sent for recognition.
   *
   * @generated from field: google.cloud.speech.v2.ExplicitDecodingConfig.AudioEncoding encoding = 1;
   */
  encoding = ExplicitDecodingConfig_AudioEncoding.AUDIO_ENCODING_UNSPECIFIED;

  /**
   * Sample rate in Hertz of the audio data sent for recognition. Valid
   * values are: 8000-48000. 16000 is optimal. For best results, set the
   * sampling rate of the audio source to 16000 Hz. If that's not possible, use
   * the native sample rate of the audio source (instead of re-sampling).
   * Supported for the following encodings:
   *
   * * LINEAR16: Headerless 16-bit signed little-endian PCM samples.
   *
   * * MULAW: Headerless 8-bit companded mulaw samples.
   *
   * * ALAW: Headerless 8-bit companded alaw samples.
   *
   * @generated from field: int32 sample_rate_hertz = 2;
   */
  sampleRateHertz = 0;

  /**
   * Number of channels present in the audio data sent for recognition.
   * Supported for the following encodings:
   *
   * * LINEAR16: Headerless 16-bit signed little-endian PCM samples.
   *
   * * MULAW: Headerless 8-bit companded mulaw samples.
   *
   * * ALAW: Headerless 8-bit companded alaw samples.
   *
   * The maximum allowed value is 8.
   *
   * @generated from field: int32 audio_channel_count = 3;
   */
  audioChannelCount = 0;

  constructor(data?: PartialMessage<ExplicitDecodingConfig>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.speech.v2.ExplicitDecodingConfig";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "encoding", kind: "enum", T: proto3.getEnumType(ExplicitDecodingConfig_AudioEncoding) },
    { no: 2, name: "sample_rate_hertz", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 3, name: "audio_channel_count", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ExplicitDecodingConfig {
    return new ExplicitDecodingConfig().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ExplicitDecodingConfig {
    return new ExplicitDecodingConfig().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ExplicitDecodingConfig {
    return new ExplicitDecodingConfig().fromJsonString(jsonString, options);
  }

  static equals(a: ExplicitDecodingConfig | PlainMessage<ExplicitDecodingConfig> | undefined, b: ExplicitDecodingConfig | PlainMessage<ExplicitDecodingConfig> | undefined): boolean {
    return proto3.util.equals(ExplicitDecodingConfig, a, b);
  }
}

/**
 * Supported audio data encodings.
 *
 * @generated from enum google.cloud.speech.v2.ExplicitDecodingConfig.AudioEncoding
 */
export enum ExplicitDecodingConfig_AudioEncoding {
  /**
   * Default value. This value is unused.
   *
   * @generated from enum value: AUDIO_ENCODING_UNSPECIFIED = 0;
   */
  AUDIO_ENCODING_UNSPECIFIED = 0,

  /**
   * Headerless 16-bit signed little-endian PCM samples.
   *
   * @generated from enum value: LINEAR16 = 1;
   */
  LINEAR16 = 1,

  /**
   * Headerless 8-bit companded mulaw samples.
   *
   * @generated from enum value: MULAW = 2;
   */
  MULAW = 2,

  /**
   * Headerless 8-bit companded alaw samples.
   *
   * @generated from enum value: ALAW = 3;
   */
  ALAW = 3,
}
// Retrieve enum metadata with: proto3.getEnumType(ExplicitDecodingConfig_AudioEncoding)
proto3.util.setEnumType(ExplicitDecodingConfig_AudioEncoding, "google.cloud.speech.v2.ExplicitDecodingConfig.AudioEncoding", [
  { no: 0, name: "AUDIO_ENCODING_UNSPECIFIED" },
  { no: 1, name: "LINEAR16" },
  { no: 2, name: "MULAW" },
  { no: 3, name: "ALAW" },
]);

/**
 * Configuration to enable speaker diarization.
 *
 * @generated from message google.cloud.speech.v2.SpeakerDiarizationConfig
 */
export class SpeakerDiarizationConfig extends Message<SpeakerDiarizationConfig> {
  /**
   * Required. Minimum number of speakers in the conversation. This range gives
   * you more flexibility by allowing the system to automatically determine the
   * correct number of speakers.
   *
   * To fix the number of speakers detected in the audio, set
   * `min_speaker_count` = `max_speaker_count`.
   *
   * @generated from field: int32 min_speaker_count = 2;
   */
  minSpeakerCount = 0;

  /**
   * Required. Maximum number of speakers in the conversation. Valid values are:
   * 1-6. Must be >= `min_speaker_count`. This range gives you more flexibility
   * by allowing the system to automatically determine the correct number of
   * speakers.
   *
   * @generated from field: int32 max_speaker_count = 3;
   */
  maxSpeakerCount = 0;

  constructor(data?: PartialMessage<SpeakerDiarizationConfig>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.speech.v2.SpeakerDiarizationConfig";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 2, name: "min_speaker_count", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 3, name: "max_speaker_count", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): SpeakerDiarizationConfig {
    return new SpeakerDiarizationConfig().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): SpeakerDiarizationConfig {
    return new SpeakerDiarizationConfig().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): SpeakerDiarizationConfig {
    return new SpeakerDiarizationConfig().fromJsonString(jsonString, options);
  }

  static equals(a: SpeakerDiarizationConfig | PlainMessage<SpeakerDiarizationConfig> | undefined, b: SpeakerDiarizationConfig | PlainMessage<SpeakerDiarizationConfig> | undefined): boolean {
    return proto3.util.equals(SpeakerDiarizationConfig, a, b);
  }
}

/**
 * Available recognition features.
 *
 * @generated from message google.cloud.speech.v2.RecognitionFeatures
 */
export class RecognitionFeatures extends Message<RecognitionFeatures> {
  /**
   * If set to `true`, the server will attempt to filter out profanities,
   * replacing all but the initial character in each filtered word with
   * asterisks, for instance, "f***". If set to `false` or omitted, profanities
   * won't be filtered out.
   *
   * @generated from field: bool profanity_filter = 1;
   */
  profanityFilter = false;

  /**
   * If `true`, the top result includes a list of words and the start and end
   * time offsets (timestamps) for those words. If `false`, no word-level time
   * offset information is returned. The default is `false`.
   *
   * @generated from field: bool enable_word_time_offsets = 2;
   */
  enableWordTimeOffsets = false;

  /**
   * If `true`, the top result includes a list of words and the confidence for
   * those words. If `false`, no word-level confidence information is returned.
   * The default is `false`.
   *
   * @generated from field: bool enable_word_confidence = 3;
   */
  enableWordConfidence = false;

  /**
   * If `true`, adds punctuation to recognition result hypotheses. This feature
   * is only available in select languages. The default `false` value does not
   * add punctuation to result hypotheses.
   *
   * @generated from field: bool enable_automatic_punctuation = 4;
   */
  enableAutomaticPunctuation = false;

  /**
   * The spoken punctuation behavior for the call. If `true`, replaces spoken
   * punctuation with the corresponding symbols in the request. For example,
   * "how are you question mark" becomes "how are you?". See
   * https://cloud.google.com/speech-to-text/docs/spoken-punctuation for
   * support. If `false`, spoken punctuation is not replaced.
   *
   * @generated from field: bool enable_spoken_punctuation = 14;
   */
  enableSpokenPunctuation = false;

  /**
   * The spoken emoji behavior for the call. If `true`, adds spoken emoji
   * formatting for the request. This will replace spoken emojis with the
   * corresponding Unicode symbols in the final transcript. If `false`, spoken
   * emojis are not replaced.
   *
   * @generated from field: bool enable_spoken_emojis = 15;
   */
  enableSpokenEmojis = false;

  /**
   * Mode for recognizing multi-channel audio.
   *
   * @generated from field: google.cloud.speech.v2.RecognitionFeatures.MultiChannelMode multi_channel_mode = 17;
   */
  multiChannelMode = RecognitionFeatures_MultiChannelMode.MULTI_CHANNEL_MODE_UNSPECIFIED;

  /**
   * Configuration to enable speaker diarization and set additional
   * parameters to make diarization better suited for your application.
   * When this is enabled, we send all the words from the beginning of the
   * audio for the top alternative in every consecutive STREAMING responses.
   * This is done in order to improve our speaker tags as our models learn to
   * identify the speakers in the conversation over time.
   * For non-streaming requests, the diarization results will be provided only
   * in the top alternative of the FINAL SpeechRecognitionResult.
   *
   * @generated from field: google.cloud.speech.v2.SpeakerDiarizationConfig diarization_config = 9;
   */
  diarizationConfig?: SpeakerDiarizationConfig;

  /**
   * Maximum number of recognition hypotheses to be returned.
   * The server may return fewer than `max_alternatives`.
   * Valid values are `0`-`30`. A value of `0` or `1` will return a maximum of
   * one. If omitted, will return a maximum of one.
   *
   * @generated from field: int32 max_alternatives = 16;
   */
  maxAlternatives = 0;

  constructor(data?: PartialMessage<RecognitionFeatures>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.speech.v2.RecognitionFeatures";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "profanity_filter", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
    { no: 2, name: "enable_word_time_offsets", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
    { no: 3, name: "enable_word_confidence", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
    { no: 4, name: "enable_automatic_punctuation", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
    { no: 14, name: "enable_spoken_punctuation", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
    { no: 15, name: "enable_spoken_emojis", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
    { no: 17, name: "multi_channel_mode", kind: "enum", T: proto3.getEnumType(RecognitionFeatures_MultiChannelMode) },
    { no: 9, name: "diarization_config", kind: "message", T: SpeakerDiarizationConfig },
    { no: 16, name: "max_alternatives", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): RecognitionFeatures {
    return new RecognitionFeatures().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): RecognitionFeatures {
    return new RecognitionFeatures().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): RecognitionFeatures {
    return new RecognitionFeatures().fromJsonString(jsonString, options);
  }

  static equals(a: RecognitionFeatures | PlainMessage<RecognitionFeatures> | undefined, b: RecognitionFeatures | PlainMessage<RecognitionFeatures> | undefined): boolean {
    return proto3.util.equals(RecognitionFeatures, a, b);
  }
}

/**
 * Options for how to recognize multi-channel audio.
 *
 * @generated from enum google.cloud.speech.v2.RecognitionFeatures.MultiChannelMode
 */
export enum RecognitionFeatures_MultiChannelMode {
  /**
   * Default value for the multi-channel mode. If the audio contains
   * multiple channels, only the first channel will be transcribed; other
   * channels will be ignored.
   *
   * @generated from enum value: MULTI_CHANNEL_MODE_UNSPECIFIED = 0;
   */
  MULTI_CHANNEL_MODE_UNSPECIFIED = 0,

  /**
   * If selected, each channel in the provided audio is transcribed
   * independently. This cannot be selected if the selected
   * [model][google.cloud.speech.v2.Recognizer.model] is `latest_short`.
   *
   * @generated from enum value: SEPARATE_RECOGNITION_PER_CHANNEL = 1;
   */
  SEPARATE_RECOGNITION_PER_CHANNEL = 1,
}
// Retrieve enum metadata with: proto3.getEnumType(RecognitionFeatures_MultiChannelMode)
proto3.util.setEnumType(RecognitionFeatures_MultiChannelMode, "google.cloud.speech.v2.RecognitionFeatures.MultiChannelMode", [
  { no: 0, name: "MULTI_CHANNEL_MODE_UNSPECIFIED" },
  { no: 1, name: "SEPARATE_RECOGNITION_PER_CHANNEL" },
]);

/**
 * Provides "hints" to the speech recognizer to favor specific words and phrases
 * in the results. PhraseSets can be specified as an inline resource, or a
 * reference to an existing PhraseSet resource.
 *
 * @generated from message google.cloud.speech.v2.SpeechAdaptation
 */
export class SpeechAdaptation extends Message<SpeechAdaptation> {
  /**
   * A list of inline or referenced PhraseSets.
   *
   * @generated from field: repeated google.cloud.speech.v2.SpeechAdaptation.AdaptationPhraseSet phrase_sets = 1;
   */
  phraseSets: SpeechAdaptation_AdaptationPhraseSet[] = [];

  /**
   * A list of inline CustomClasses. Existing CustomClass resources can be
   * referenced directly in a PhraseSet.
   *
   * @generated from field: repeated google.cloud.speech.v2.CustomClass custom_classes = 2;
   */
  customClasses: CustomClass[] = [];

  constructor(data?: PartialMessage<SpeechAdaptation>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.speech.v2.SpeechAdaptation";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "phrase_sets", kind: "message", T: SpeechAdaptation_AdaptationPhraseSet, repeated: true },
    { no: 2, name: "custom_classes", kind: "message", T: CustomClass, repeated: true },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): SpeechAdaptation {
    return new SpeechAdaptation().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): SpeechAdaptation {
    return new SpeechAdaptation().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): SpeechAdaptation {
    return new SpeechAdaptation().fromJsonString(jsonString, options);
  }

  static equals(a: SpeechAdaptation | PlainMessage<SpeechAdaptation> | undefined, b: SpeechAdaptation | PlainMessage<SpeechAdaptation> | undefined): boolean {
    return proto3.util.equals(SpeechAdaptation, a, b);
  }
}

/**
 * A biasing PhraseSet, which can be either a string referencing the name of
 * an existing PhraseSets resource, or an inline definition of a PhraseSet.
 *
 * @generated from message google.cloud.speech.v2.SpeechAdaptation.AdaptationPhraseSet
 */
export class SpeechAdaptation_AdaptationPhraseSet extends Message<SpeechAdaptation_AdaptationPhraseSet> {
  /**
   * @generated from oneof google.cloud.speech.v2.SpeechAdaptation.AdaptationPhraseSet.value
   */
  value: {
    /**
     * The name of an existing PhraseSet resource. The user must have read
     * access to the resource and it must not be deleted.
     *
     * @generated from field: string phrase_set = 1;
     */
    value: string;
    case: "phraseSet";
  } | {
    /**
     * An inline defined PhraseSet.
     *
     * @generated from field: google.cloud.speech.v2.PhraseSet inline_phrase_set = 2;
     */
    value: PhraseSet;
    case: "inlinePhraseSet";
  } | { case: undefined; value?: undefined } = { case: undefined };

  constructor(data?: PartialMessage<SpeechAdaptation_AdaptationPhraseSet>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.speech.v2.SpeechAdaptation.AdaptationPhraseSet";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "phrase_set", kind: "scalar", T: 9 /* ScalarType.STRING */, oneof: "value" },
    { no: 2, name: "inline_phrase_set", kind: "message", T: PhraseSet, oneof: "value" },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): SpeechAdaptation_AdaptationPhraseSet {
    return new SpeechAdaptation_AdaptationPhraseSet().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): SpeechAdaptation_AdaptationPhraseSet {
    return new SpeechAdaptation_AdaptationPhraseSet().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): SpeechAdaptation_AdaptationPhraseSet {
    return new SpeechAdaptation_AdaptationPhraseSet().fromJsonString(jsonString, options);
  }

  static equals(a: SpeechAdaptation_AdaptationPhraseSet | PlainMessage<SpeechAdaptation_AdaptationPhraseSet> | undefined, b: SpeechAdaptation_AdaptationPhraseSet | PlainMessage<SpeechAdaptation_AdaptationPhraseSet> | undefined): boolean {
    return proto3.util.equals(SpeechAdaptation_AdaptationPhraseSet, a, b);
  }
}

/**
 * Provides information to the Recognizer that specifies how to process the
 * recognition request.
 *
 * @generated from message google.cloud.speech.v2.RecognitionConfig
 */
export class RecognitionConfig extends Message<RecognitionConfig> {
  /**
   * Decoding parameters for audio being sent for recognition.
   *
   * @generated from oneof google.cloud.speech.v2.RecognitionConfig.decoding_config
   */
  decodingConfig: {
    /**
     * Automatically detect decoding parameters.
     * Preferred for supported formats.
     *
     * @generated from field: google.cloud.speech.v2.AutoDetectDecodingConfig auto_decoding_config = 7;
     */
    value: AutoDetectDecodingConfig;
    case: "autoDecodingConfig";
  } | {
    /**
     * Explicitly specified decoding parameters.
     * Required if using headerless PCM audio (linear16, mulaw, alaw).
     *
     * @generated from field: google.cloud.speech.v2.ExplicitDecodingConfig explicit_decoding_config = 8;
     */
    value: ExplicitDecodingConfig;
    case: "explicitDecodingConfig";
  } | { case: undefined; value?: undefined } = { case: undefined };

  /**
   * Speech recognition features to enable.
   *
   * @generated from field: google.cloud.speech.v2.RecognitionFeatures features = 2;
   */
  features?: RecognitionFeatures;

  /**
   * Speech adaptation context that weights recognizer predictions for specific
   * words and phrases.
   *
   * @generated from field: google.cloud.speech.v2.SpeechAdaptation adaptation = 6;
   */
  adaptation?: SpeechAdaptation;

  constructor(data?: PartialMessage<RecognitionConfig>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.speech.v2.RecognitionConfig";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 7, name: "auto_decoding_config", kind: "message", T: AutoDetectDecodingConfig, oneof: "decoding_config" },
    { no: 8, name: "explicit_decoding_config", kind: "message", T: ExplicitDecodingConfig, oneof: "decoding_config" },
    { no: 2, name: "features", kind: "message", T: RecognitionFeatures },
    { no: 6, name: "adaptation", kind: "message", T: SpeechAdaptation },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): RecognitionConfig {
    return new RecognitionConfig().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): RecognitionConfig {
    return new RecognitionConfig().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): RecognitionConfig {
    return new RecognitionConfig().fromJsonString(jsonString, options);
  }

  static equals(a: RecognitionConfig | PlainMessage<RecognitionConfig> | undefined, b: RecognitionConfig | PlainMessage<RecognitionConfig> | undefined): boolean {
    return proto3.util.equals(RecognitionConfig, a, b);
  }
}

/**
 * Request message for the
 * [Recognize][google.cloud.speech.v2.Speech.Recognize] method. Either
 * `content` or `uri` must be supplied. Supplying both or neither returns
 * [INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT]. See [content
 * limits](https://cloud.google.com/speech-to-text/quotas#content).
 *
 * @generated from message google.cloud.speech.v2.RecognizeRequest
 */
export class RecognizeRequest extends Message<RecognizeRequest> {
  /**
   * Required. The name of the Recognizer to use during recognition. The
   * expected format is
   * `projects/{project}/locations/{location}/recognizers/{recognizer}`.
   *
   * @generated from field: string recognizer = 3;
   */
  recognizer = "";

  /**
   * Features and audio metadata to use for the Automatic Speech Recognition.
   * This field in combination with the
   * [config_mask][google.cloud.speech.v2.RecognizeRequest.config_mask] field
   * can be used to override parts of the
   * [default_recognition_config][google.cloud.speech.v2.Recognizer.default_recognition_config]
   * of the Recognizer resource.
   *
   * @generated from field: google.cloud.speech.v2.RecognitionConfig config = 1;
   */
  config?: RecognitionConfig;

  /**
   * The list of fields in
   * [config][google.cloud.speech.v2.RecognizeRequest.config] that override the
   * values in the
   * [default_recognition_config][google.cloud.speech.v2.Recognizer.default_recognition_config]
   * of the recognizer during this recognition request. If no mask is provided,
   * all non-default valued fields in
   * [config][google.cloud.speech.v2.RecognizeRequest.config] override the
   * values in the recognizer for this recognition request. If a mask is
   * provided, only the fields listed in the mask override the config in the
   * recognizer for this recognition request. If a wildcard (`*`) is provided,
   * [config][google.cloud.speech.v2.RecognizeRequest.config] completely
   * overrides and replaces the config in the recognizer for this recognition
   * request.
   *
   * @generated from field: google.protobuf.FieldMask config_mask = 8;
   */
  configMask?: FieldMask;

  /**
   * The audio source, which is either inline content or a Google Cloud
   * Storage URI.
   *
   * @generated from oneof google.cloud.speech.v2.RecognizeRequest.audio_source
   */
  audioSource: {
    /**
     * The audio data bytes encoded as specified in
     * [RecognitionConfig][google.cloud.speech.v2.RecognitionConfig]. As
     * with all bytes fields, proto buffers use a pure binary representation,
     * whereas JSON representations use base64.
     *
     * @generated from field: bytes content = 5;
     */
    value: Uint8Array;
    case: "content";
  } | {
    /**
     * URI that points to a file that contains audio data bytes as specified in
     * [RecognitionConfig][google.cloud.speech.v2.RecognitionConfig]. The file
     * must not be compressed (for example, gzip). Currently, only Google Cloud
     * Storage URIs are supported, which must be specified in the following
     * format: `gs://bucket_name/object_name` (other URI formats return
     * [INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT]). For more
     * information, see [Request
     * URIs](https://cloud.google.com/storage/docs/reference-uris).
     *
     * @generated from field: string uri = 6;
     */
    value: string;
    case: "uri";
  } | { case: undefined; value?: undefined } = { case: undefined };

  constructor(data?: PartialMessage<RecognizeRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.speech.v2.RecognizeRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 3, name: "recognizer", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 1, name: "config", kind: "message", T: RecognitionConfig },
    { no: 8, name: "config_mask", kind: "message", T: FieldMask },
    { no: 5, name: "content", kind: "scalar", T: 12 /* ScalarType.BYTES */, oneof: "audio_source" },
    { no: 6, name: "uri", kind: "scalar", T: 9 /* ScalarType.STRING */, oneof: "audio_source" },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): RecognizeRequest {
    return new RecognizeRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): RecognizeRequest {
    return new RecognizeRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): RecognizeRequest {
    return new RecognizeRequest().fromJsonString(jsonString, options);
  }

  static equals(a: RecognizeRequest | PlainMessage<RecognizeRequest> | undefined, b: RecognizeRequest | PlainMessage<RecognizeRequest> | undefined): boolean {
    return proto3.util.equals(RecognizeRequest, a, b);
  }
}

/**
 * Metadata about the recognition request and response.
 *
 * @generated from message google.cloud.speech.v2.RecognitionResponseMetadata
 */
export class RecognitionResponseMetadata extends Message<RecognitionResponseMetadata> {
  /**
   * When available, billed audio seconds for the corresponding request.
   *
   * @generated from field: google.protobuf.Duration total_billed_duration = 6;
   */
  totalBilledDuration?: Duration;

  constructor(data?: PartialMessage<RecognitionResponseMetadata>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.speech.v2.RecognitionResponseMetadata";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 6, name: "total_billed_duration", kind: "message", T: Duration },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): RecognitionResponseMetadata {
    return new RecognitionResponseMetadata().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): RecognitionResponseMetadata {
    return new RecognitionResponseMetadata().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): RecognitionResponseMetadata {
    return new RecognitionResponseMetadata().fromJsonString(jsonString, options);
  }

  static equals(a: RecognitionResponseMetadata | PlainMessage<RecognitionResponseMetadata> | undefined, b: RecognitionResponseMetadata | PlainMessage<RecognitionResponseMetadata> | undefined): boolean {
    return proto3.util.equals(RecognitionResponseMetadata, a, b);
  }
}

/**
 * Alternative hypotheses (a.k.a. n-best list).
 *
 * @generated from message google.cloud.speech.v2.SpeechRecognitionAlternative
 */
export class SpeechRecognitionAlternative extends Message<SpeechRecognitionAlternative> {
  /**
   * Transcript text representing the words that the user spoke.
   *
   * @generated from field: string transcript = 1;
   */
  transcript = "";

  /**
   * The confidence estimate between 0.0 and 1.0. A higher number
   * indicates an estimated greater likelihood that the recognized words are
   * correct. This field is set only for the top alternative of a non-streaming
   * result or, of a streaming result where
   * [is_final][google.cloud.speech.v2.StreamingRecognitionResult.is_final] is
   * set to `true`. This field is not guaranteed to be accurate and users should
   * not rely on it to be always provided. The default of 0.0 is a sentinel
   * value indicating `confidence` was not set.
   *
   * @generated from field: float confidence = 2;
   */
  confidence = 0;

  /**
   * A list of word-specific information for each recognized word.
   * When the
   * [SpeakerDiarizationConfig][google.cloud.speech.v2.SpeakerDiarizationConfig]
   * is set, you will see all the words from the beginning of the audio.
   *
   * @generated from field: repeated google.cloud.speech.v2.WordInfo words = 3;
   */
  words: WordInfo[] = [];

  constructor(data?: PartialMessage<SpeechRecognitionAlternative>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.speech.v2.SpeechRecognitionAlternative";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "transcript", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "confidence", kind: "scalar", T: 2 /* ScalarType.FLOAT */ },
    { no: 3, name: "words", kind: "message", T: WordInfo, repeated: true },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): SpeechRecognitionAlternative {
    return new SpeechRecognitionAlternative().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): SpeechRecognitionAlternative {
    return new SpeechRecognitionAlternative().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): SpeechRecognitionAlternative {
    return new SpeechRecognitionAlternative().fromJsonString(jsonString, options);
  }

  static equals(a: SpeechRecognitionAlternative | PlainMessage<SpeechRecognitionAlternative> | undefined, b: SpeechRecognitionAlternative | PlainMessage<SpeechRecognitionAlternative> | undefined): boolean {
    return proto3.util.equals(SpeechRecognitionAlternative, a, b);
  }
}

/**
 * Word-specific information for recognized words.
 *
 * @generated from message google.cloud.speech.v2.WordInfo
 */
export class WordInfo extends Message<WordInfo> {
  /**
   * Time offset relative to the beginning of the audio,
   * and corresponding to the start of the spoken word.
   * This field is only set if
   * [enable_word_time_offsets][google.cloud.speech.v2.RecognitionFeatures.enable_word_time_offsets]
   * is `true` and only in the top hypothesis. This is an experimental feature
   * and the accuracy of the time offset can vary.
   *
   * @generated from field: google.protobuf.Duration start_offset = 1;
   */
  startOffset?: Duration;

  /**
   * Time offset relative to the beginning of the audio,
   * and corresponding to the end of the spoken word.
   * This field is only set if
   * [enable_word_time_offsets][google.cloud.speech.v2.RecognitionFeatures.enable_word_time_offsets]
   * is `true` and only in the top hypothesis. This is an experimental feature
   * and the accuracy of the time offset can vary.
   *
   * @generated from field: google.protobuf.Duration end_offset = 2;
   */
  endOffset?: Duration;

  /**
   * The word corresponding to this set of information.
   *
   * @generated from field: string word = 3;
   */
  word = "";

  /**
   * The confidence estimate between 0.0 and 1.0. A higher number
   * indicates an estimated greater likelihood that the recognized words are
   * correct. This field is set only for the top alternative of a non-streaming
   * result or, of a streaming result where
   * [is_final][google.cloud.speech.v2.StreamingRecognitionResult.is_final] is
   * set to `true`. This field is not guaranteed to be accurate and users should
   * not rely on it to be always provided. The default of 0.0 is a sentinel
   * value indicating `confidence` was not set.
   *
   * @generated from field: float confidence = 4;
   */
  confidence = 0;

  /**
   * A distinct label is assigned for every speaker within the audio. This field
   * specifies which one of those speakers was detected to have spoken this
   * word. `speaker_label` is set if
   * [SpeakerDiarizationConfig][google.cloud.speech.v2.SpeakerDiarizationConfig]
   * is given and only in the top alternative.
   *
   * @generated from field: string speaker_label = 6;
   */
  speakerLabel = "";

  constructor(data?: PartialMessage<WordInfo>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.speech.v2.WordInfo";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "start_offset", kind: "message", T: Duration },
    { no: 2, name: "end_offset", kind: "message", T: Duration },
    { no: 3, name: "word", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 4, name: "confidence", kind: "scalar", T: 2 /* ScalarType.FLOAT */ },
    { no: 6, name: "speaker_label", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): WordInfo {
    return new WordInfo().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): WordInfo {
    return new WordInfo().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): WordInfo {
    return new WordInfo().fromJsonString(jsonString, options);
  }

  static equals(a: WordInfo | PlainMessage<WordInfo> | undefined, b: WordInfo | PlainMessage<WordInfo> | undefined): boolean {
    return proto3.util.equals(WordInfo, a, b);
  }
}

/**
 * A speech recognition result corresponding to a portion of the audio.
 *
 * @generated from message google.cloud.speech.v2.SpeechRecognitionResult
 */
export class SpeechRecognitionResult extends Message<SpeechRecognitionResult> {
  /**
   * May contain one or more recognition hypotheses. These alternatives are
   * ordered in terms of accuracy, with the top (first) alternative being the
   * most probable, as ranked by the recognizer.
   *
   * @generated from field: repeated google.cloud.speech.v2.SpeechRecognitionAlternative alternatives = 1;
   */
  alternatives: SpeechRecognitionAlternative[] = [];

  /**
   * For multi-channel audio, this is the channel number corresponding to the
   * recognized result for the audio from that channel.
   * For `audio_channel_count` = `N`, its output values can range from `1` to
   * `N`.
   *
   * @generated from field: int32 channel_tag = 2;
   */
  channelTag = 0;

  /**
   * Time offset of the end of this result relative to the beginning of the
   * audio.
   *
   * @generated from field: google.protobuf.Duration result_end_offset = 4;
   */
  resultEndOffset?: Duration;

  /**
   * Output only. The [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt)
   * language tag of the language in this result. This language code was
   * detected to have the most likelihood of being spoken in the audio.
   *
   * @generated from field: string language_code = 5;
   */
  languageCode = "";

  constructor(data?: PartialMessage<SpeechRecognitionResult>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.speech.v2.SpeechRecognitionResult";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "alternatives", kind: "message", T: SpeechRecognitionAlternative, repeated: true },
    { no: 2, name: "channel_tag", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 4, name: "result_end_offset", kind: "message", T: Duration },
    { no: 5, name: "language_code", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): SpeechRecognitionResult {
    return new SpeechRecognitionResult().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): SpeechRecognitionResult {
    return new SpeechRecognitionResult().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): SpeechRecognitionResult {
    return new SpeechRecognitionResult().fromJsonString(jsonString, options);
  }

  static equals(a: SpeechRecognitionResult | PlainMessage<SpeechRecognitionResult> | undefined, b: SpeechRecognitionResult | PlainMessage<SpeechRecognitionResult> | undefined): boolean {
    return proto3.util.equals(SpeechRecognitionResult, a, b);
  }
}

/**
 * Response message for the
 * [Recognize][google.cloud.speech.v2.Speech.Recognize] method.
 *
 * @generated from message google.cloud.speech.v2.RecognizeResponse
 */
export class RecognizeResponse extends Message<RecognizeResponse> {
  /**
   * Sequential list of transcription results corresponding to sequential
   * portions of audio.
   *
   * @generated from field: repeated google.cloud.speech.v2.SpeechRecognitionResult results = 3;
   */
  results: SpeechRecognitionResult[] = [];

  /**
   * Metadata about the recognition.
   *
   * @generated from field: google.cloud.speech.v2.RecognitionResponseMetadata metadata = 2;
   */
  metadata?: RecognitionResponseMetadata;

  constructor(data?: PartialMessage<RecognizeResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.speech.v2.RecognizeResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 3, name: "results", kind: "message", T: SpeechRecognitionResult, repeated: true },
    { no: 2, name: "metadata", kind: "message", T: RecognitionResponseMetadata },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): RecognizeResponse {
    return new RecognizeResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): RecognizeResponse {
    return new RecognizeResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): RecognizeResponse {
    return new RecognizeResponse().fromJsonString(jsonString, options);
  }

  static equals(a: RecognizeResponse | PlainMessage<RecognizeResponse> | undefined, b: RecognizeResponse | PlainMessage<RecognizeResponse> | undefined): boolean {
    return proto3.util.equals(RecognizeResponse, a, b);
  }
}

/**
 * Available recognition features specific to streaming recognition requests.
 *
 * @generated from message google.cloud.speech.v2.StreamingRecognitionFeatures
 */
export class StreamingRecognitionFeatures extends Message<StreamingRecognitionFeatures> {
  /**
   * If `true`, responses with voice activity speech events will be returned as
   * they are detected.
   *
   * @generated from field: bool enable_voice_activity_events = 1;
   */
  enableVoiceActivityEvents = false;

  /**
   * Whether or not to stream interim results to the client. If set to true,
   * interim results will be streamed to the client. Otherwise, only the final
   * response will be streamed back.
   *
   * @generated from field: bool interim_results = 2;
   */
  interimResults = false;

  /**
   * If set, the server will automatically close the stream after the specified
   * duration has elapsed after the last VOICE_ACTIVITY speech event has been
   * sent. The field `voice_activity_events` must also be set to true.
   *
   * @generated from field: google.cloud.speech.v2.StreamingRecognitionFeatures.VoiceActivityTimeout voice_activity_timeout = 3;
   */
  voiceActivityTimeout?: StreamingRecognitionFeatures_VoiceActivityTimeout;

  constructor(data?: PartialMessage<StreamingRecognitionFeatures>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.speech.v2.StreamingRecognitionFeatures";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "enable_voice_activity_events", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
    { no: 2, name: "interim_results", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
    { no: 3, name: "voice_activity_timeout", kind: "message", T: StreamingRecognitionFeatures_VoiceActivityTimeout },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): StreamingRecognitionFeatures {
    return new StreamingRecognitionFeatures().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): StreamingRecognitionFeatures {
    return new StreamingRecognitionFeatures().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): StreamingRecognitionFeatures {
    return new StreamingRecognitionFeatures().fromJsonString(jsonString, options);
  }

  static equals(a: StreamingRecognitionFeatures | PlainMessage<StreamingRecognitionFeatures> | undefined, b: StreamingRecognitionFeatures | PlainMessage<StreamingRecognitionFeatures> | undefined): boolean {
    return proto3.util.equals(StreamingRecognitionFeatures, a, b);
  }
}

/**
 * Events that a timeout can be set on for voice activity.
 *
 * @generated from message google.cloud.speech.v2.StreamingRecognitionFeatures.VoiceActivityTimeout
 */
export class StreamingRecognitionFeatures_VoiceActivityTimeout extends Message<StreamingRecognitionFeatures_VoiceActivityTimeout> {
  /**
   * Duration to timeout the stream if no speech begins. If this is set and
   * no speech is detected in this duration at the start of the stream, the
   * server will close the stream.
   *
   * @generated from field: google.protobuf.Duration speech_start_timeout = 1;
   */
  speechStartTimeout?: Duration;

  /**
   * Duration to timeout the stream after speech ends. If this is set and no
   * speech is detected in this duration after speech was detected, the server
   * will close the stream.
   *
   * @generated from field: google.protobuf.Duration speech_end_timeout = 2;
   */
  speechEndTimeout?: Duration;

  constructor(data?: PartialMessage<StreamingRecognitionFeatures_VoiceActivityTimeout>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.speech.v2.StreamingRecognitionFeatures.VoiceActivityTimeout";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "speech_start_timeout", kind: "message", T: Duration },
    { no: 2, name: "speech_end_timeout", kind: "message", T: Duration },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): StreamingRecognitionFeatures_VoiceActivityTimeout {
    return new StreamingRecognitionFeatures_VoiceActivityTimeout().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): StreamingRecognitionFeatures_VoiceActivityTimeout {
    return new StreamingRecognitionFeatures_VoiceActivityTimeout().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): StreamingRecognitionFeatures_VoiceActivityTimeout {
    return new StreamingRecognitionFeatures_VoiceActivityTimeout().fromJsonString(jsonString, options);
  }

  static equals(a: StreamingRecognitionFeatures_VoiceActivityTimeout | PlainMessage<StreamingRecognitionFeatures_VoiceActivityTimeout> | undefined, b: StreamingRecognitionFeatures_VoiceActivityTimeout | PlainMessage<StreamingRecognitionFeatures_VoiceActivityTimeout> | undefined): boolean {
    return proto3.util.equals(StreamingRecognitionFeatures_VoiceActivityTimeout, a, b);
  }
}

/**
 * Provides configuration information for the StreamingRecognize request.
 *
 * @generated from message google.cloud.speech.v2.StreamingRecognitionConfig
 */
export class StreamingRecognitionConfig extends Message<StreamingRecognitionConfig> {
  /**
   * Required. Features and audio metadata to use for the Automatic Speech
   * Recognition. This field in combination with the
   * [config_mask][google.cloud.speech.v2.StreamingRecognitionConfig.config_mask]
   * field can be used to override parts of the
   * [default_recognition_config][google.cloud.speech.v2.Recognizer.default_recognition_config]
   * of the Recognizer resource.
   *
   * @generated from field: google.cloud.speech.v2.RecognitionConfig config = 1;
   */
  config?: RecognitionConfig;

  /**
   * The list of fields in
   * [config][google.cloud.speech.v2.StreamingRecognitionConfig.config] that
   * override the values in the
   * [default_recognition_config][google.cloud.speech.v2.Recognizer.default_recognition_config]
   * of the recognizer during this recognition request. If no mask is provided,
   * all non-default valued fields in
   * [config][google.cloud.speech.v2.StreamingRecognitionConfig.config] override
   * the values in the Recognizer for this recognition request. If a mask is
   * provided, only the fields listed in the mask override the config in the
   * Recognizer for this recognition request. If a wildcard (`*`) is provided,
   * [config][google.cloud.speech.v2.StreamingRecognitionConfig.config]
   * completely overrides and replaces the config in the recognizer for this
   * recognition request.
   *
   * @generated from field: google.protobuf.FieldMask config_mask = 3;
   */
  configMask?: FieldMask;

  /**
   * Speech recognition features to enable specific to streaming audio
   * recognition requests.
   *
   * @generated from field: google.cloud.speech.v2.StreamingRecognitionFeatures streaming_features = 2;
   */
  streamingFeatures?: StreamingRecognitionFeatures;

  constructor(data?: PartialMessage<StreamingRecognitionConfig>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.speech.v2.StreamingRecognitionConfig";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "config", kind: "message", T: RecognitionConfig },
    { no: 3, name: "config_mask", kind: "message", T: FieldMask },
    { no: 2, name: "streaming_features", kind: "message", T: StreamingRecognitionFeatures },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): StreamingRecognitionConfig {
    return new StreamingRecognitionConfig().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): StreamingRecognitionConfig {
    return new StreamingRecognitionConfig().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): StreamingRecognitionConfig {
    return new StreamingRecognitionConfig().fromJsonString(jsonString, options);
  }

  static equals(a: StreamingRecognitionConfig | PlainMessage<StreamingRecognitionConfig> | undefined, b: StreamingRecognitionConfig | PlainMessage<StreamingRecognitionConfig> | undefined): boolean {
    return proto3.util.equals(StreamingRecognitionConfig, a, b);
  }
}

/**
 * Request message for the
 * [StreamingRecognize][google.cloud.speech.v2.Speech.StreamingRecognize]
 * method. Multiple
 * [StreamingRecognizeRequest][google.cloud.speech.v2.StreamingRecognizeRequest]
 * messages are sent. The first message must contain a
 * [recognizer][google.cloud.speech.v2.StreamingRecognizeRequest.recognizer] and
 * optionally a
 * [streaming_config][google.cloud.speech.v2.StreamingRecognizeRequest.streaming_config]
 * message and must not contain
 * [audio][google.cloud.speech.v2.StreamingRecognizeRequest.audio]. All
 * subsequent messages must contain
 * [audio][google.cloud.speech.v2.StreamingRecognizeRequest.audio] and must not
 * contain a
 * [streaming_config][google.cloud.speech.v2.StreamingRecognizeRequest.streaming_config]
 * message.
 *
 * @generated from message google.cloud.speech.v2.StreamingRecognizeRequest
 */
export class StreamingRecognizeRequest extends Message<StreamingRecognizeRequest> {
  /**
   * Required. Streaming recognition should start with an initial request having
   * a `recognizer`. Subsequent requests carry the audio data to be recognized.
   *
   * The initial request with configuration can be omitted if the Recognizer
   * being used has a
   * [default_recognition_config][google.cloud.speech.v2.Recognizer.default_recognition_config].
   *
   * @generated from field: string recognizer = 3;
   */
  recognizer = "";

  /**
   * @generated from oneof google.cloud.speech.v2.StreamingRecognizeRequest.streaming_request
   */
  streamingRequest: {
    /**
     * StreamingRecognitionConfig to be used in this recognition attempt.
     * If provided, it will override the default RecognitionConfig stored in the
     * Recognizer.
     *
     * @generated from field: google.cloud.speech.v2.StreamingRecognitionConfig streaming_config = 6;
     */
    value: StreamingRecognitionConfig;
    case: "streamingConfig";
  } | {
    /**
     * Inline audio bytes to be Recognized.
     * Maximum size for this field is 15 KB per request.
     *
     * @generated from field: bytes audio = 5;
     */
    value: Uint8Array;
    case: "audio";
  } | { case: undefined; value?: undefined } = { case: undefined };

  constructor(data?: PartialMessage<StreamingRecognizeRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.speech.v2.StreamingRecognizeRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 3, name: "recognizer", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 6, name: "streaming_config", kind: "message", T: StreamingRecognitionConfig, oneof: "streaming_request" },
    { no: 5, name: "audio", kind: "scalar", T: 12 /* ScalarType.BYTES */, oneof: "streaming_request" },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): StreamingRecognizeRequest {
    return new StreamingRecognizeRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): StreamingRecognizeRequest {
    return new StreamingRecognizeRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): StreamingRecognizeRequest {
    return new StreamingRecognizeRequest().fromJsonString(jsonString, options);
  }

  static equals(a: StreamingRecognizeRequest | PlainMessage<StreamingRecognizeRequest> | undefined, b: StreamingRecognizeRequest | PlainMessage<StreamingRecognizeRequest> | undefined): boolean {
    return proto3.util.equals(StreamingRecognizeRequest, a, b);
  }
}

/**
 * Request message for the
 * [BatchRecognize][google.cloud.speech.v2.Speech.BatchRecognize]
 * method.
 *
 * @generated from message google.cloud.speech.v2.BatchRecognizeRequest
 */
export class BatchRecognizeRequest extends Message<BatchRecognizeRequest> {
  /**
   * Required. Resource name of the recognizer to be used for ASR.
   *
   * @generated from field: string recognizer = 1;
   */
  recognizer = "";

  /**
   * Features and audio metadata to use for the Automatic Speech Recognition.
   * This field in combination with the
   * [config_mask][google.cloud.speech.v2.BatchRecognizeRequest.config_mask]
   * field can be used to override parts of the
   * [default_recognition_config][google.cloud.speech.v2.Recognizer.default_recognition_config]
   * of the Recognizer resource.
   *
   * @generated from field: google.cloud.speech.v2.RecognitionConfig config = 4;
   */
  config?: RecognitionConfig;

  /**
   * The list of fields in
   * [config][google.cloud.speech.v2.BatchRecognizeRequest.config] that override
   * the values in the
   * [default_recognition_config][google.cloud.speech.v2.Recognizer.default_recognition_config]
   * of the recognizer during this recognition request. If no mask is provided,
   * all given fields in
   * [config][google.cloud.speech.v2.BatchRecognizeRequest.config] override the
   * values in the recognizer for this recognition request. If a mask is
   * provided, only the fields listed in the mask override the config in the
   * recognizer for this recognition request. If a wildcard (`*`) is provided,
   * [config][google.cloud.speech.v2.BatchRecognizeRequest.config] completely
   * overrides and replaces the config in the recognizer for this recognition
   * request.
   *
   * @generated from field: google.protobuf.FieldMask config_mask = 5;
   */
  configMask?: FieldMask;

  /**
   * Audio files with file metadata for ASR.
   * The maximum number of files allowed to be specified is 5.
   *
   * @generated from field: repeated google.cloud.speech.v2.BatchRecognizeFileMetadata files = 3;
   */
  files: BatchRecognizeFileMetadata[] = [];

  /**
   * Configuration options for where to output the transcripts of each file.
   *
   * @generated from field: google.cloud.speech.v2.RecognitionOutputConfig recognition_output_config = 6;
   */
  recognitionOutputConfig?: RecognitionOutputConfig;

  constructor(data?: PartialMessage<BatchRecognizeRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.speech.v2.BatchRecognizeRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "recognizer", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 4, name: "config", kind: "message", T: RecognitionConfig },
    { no: 5, name: "config_mask", kind: "message", T: FieldMask },
    { no: 3, name: "files", kind: "message", T: BatchRecognizeFileMetadata, repeated: true },
    { no: 6, name: "recognition_output_config", kind: "message", T: RecognitionOutputConfig },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): BatchRecognizeRequest {
    return new BatchRecognizeRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): BatchRecognizeRequest {
    return new BatchRecognizeRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): BatchRecognizeRequest {
    return new BatchRecognizeRequest().fromJsonString(jsonString, options);
  }

  static equals(a: BatchRecognizeRequest | PlainMessage<BatchRecognizeRequest> | undefined, b: BatchRecognizeRequest | PlainMessage<BatchRecognizeRequest> | undefined): boolean {
    return proto3.util.equals(BatchRecognizeRequest, a, b);
  }
}

/**
 * Output configurations for Cloud Storage.
 *
 * @generated from message google.cloud.speech.v2.GcsOutputConfig
 */
export class GcsOutputConfig extends Message<GcsOutputConfig> {
  /**
   * The Cloud Storage URI prefix with which recognition results will be
   * written.
   *
   * @generated from field: string uri = 1;
   */
  uri = "";

  constructor(data?: PartialMessage<GcsOutputConfig>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.speech.v2.GcsOutputConfig";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "uri", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): GcsOutputConfig {
    return new GcsOutputConfig().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): GcsOutputConfig {
    return new GcsOutputConfig().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): GcsOutputConfig {
    return new GcsOutputConfig().fromJsonString(jsonString, options);
  }

  static equals(a: GcsOutputConfig | PlainMessage<GcsOutputConfig> | undefined, b: GcsOutputConfig | PlainMessage<GcsOutputConfig> | undefined): boolean {
    return proto3.util.equals(GcsOutputConfig, a, b);
  }
}

/**
 * Output configurations for inline response.
 *
 * @generated from message google.cloud.speech.v2.InlineOutputConfig
 */
export class InlineOutputConfig extends Message<InlineOutputConfig> {
  constructor(data?: PartialMessage<InlineOutputConfig>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.speech.v2.InlineOutputConfig";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): InlineOutputConfig {
    return new InlineOutputConfig().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): InlineOutputConfig {
    return new InlineOutputConfig().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): InlineOutputConfig {
    return new InlineOutputConfig().fromJsonString(jsonString, options);
  }

  static equals(a: InlineOutputConfig | PlainMessage<InlineOutputConfig> | undefined, b: InlineOutputConfig | PlainMessage<InlineOutputConfig> | undefined): boolean {
    return proto3.util.equals(InlineOutputConfig, a, b);
  }
}

/**
 * Configuration options for the output(s) of recognition.
 *
 * @generated from message google.cloud.speech.v2.RecognitionOutputConfig
 */
export class RecognitionOutputConfig extends Message<RecognitionOutputConfig> {
  /**
   * @generated from oneof google.cloud.speech.v2.RecognitionOutputConfig.output
   */
  output: {
    /**
     * If this message is populated, recognition results are written to the
     * provided Google Cloud Storage URI.
     *
     * @generated from field: google.cloud.speech.v2.GcsOutputConfig gcs_output_config = 1;
     */
    value: GcsOutputConfig;
    case: "gcsOutputConfig";
  } | {
    /**
     * If this message is populated, recognition results are provided in the
     * [BatchRecognizeResponse][google.cloud.speech.v2.BatchRecognizeResponse]
     * message of the Operation when completed. This is only supported when
     * calling [BatchRecognize][google.cloud.speech.v2.Speech.BatchRecognize]
     * with just one audio file.
     *
     * @generated from field: google.cloud.speech.v2.InlineOutputConfig inline_response_config = 2;
     */
    value: InlineOutputConfig;
    case: "inlineResponseConfig";
  } | { case: undefined; value?: undefined } = { case: undefined };

  constructor(data?: PartialMessage<RecognitionOutputConfig>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.speech.v2.RecognitionOutputConfig";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "gcs_output_config", kind: "message", T: GcsOutputConfig, oneof: "output" },
    { no: 2, name: "inline_response_config", kind: "message", T: InlineOutputConfig, oneof: "output" },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): RecognitionOutputConfig {
    return new RecognitionOutputConfig().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): RecognitionOutputConfig {
    return new RecognitionOutputConfig().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): RecognitionOutputConfig {
    return new RecognitionOutputConfig().fromJsonString(jsonString, options);
  }

  static equals(a: RecognitionOutputConfig | PlainMessage<RecognitionOutputConfig> | undefined, b: RecognitionOutputConfig | PlainMessage<RecognitionOutputConfig> | undefined): boolean {
    return proto3.util.equals(RecognitionOutputConfig, a, b);
  }
}

/**
 * Response message for
 * [BatchRecognize][google.cloud.speech.v2.Speech.BatchRecognize] that is
 * packaged into a longrunning [Operation][google.longrunning.Operation].
 *
 * @generated from message google.cloud.speech.v2.BatchRecognizeResponse
 */
export class BatchRecognizeResponse extends Message<BatchRecognizeResponse> {
  /**
   * Map from filename to the final result for that file.
   *
   * @generated from field: map<string, google.cloud.speech.v2.BatchRecognizeFileResult> results = 1;
   */
  results: { [key: string]: BatchRecognizeFileResult } = {};

  /**
   * When available, billed audio seconds for the corresponding request.
   *
   * @generated from field: google.protobuf.Duration total_billed_duration = 2;
   */
  totalBilledDuration?: Duration;

  constructor(data?: PartialMessage<BatchRecognizeResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.speech.v2.BatchRecognizeResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "results", kind: "map", K: 9 /* ScalarType.STRING */, V: {kind: "message", T: BatchRecognizeFileResult} },
    { no: 2, name: "total_billed_duration", kind: "message", T: Duration },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): BatchRecognizeResponse {
    return new BatchRecognizeResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): BatchRecognizeResponse {
    return new BatchRecognizeResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): BatchRecognizeResponse {
    return new BatchRecognizeResponse().fromJsonString(jsonString, options);
  }

  static equals(a: BatchRecognizeResponse | PlainMessage<BatchRecognizeResponse> | undefined, b: BatchRecognizeResponse | PlainMessage<BatchRecognizeResponse> | undefined): boolean {
    return proto3.util.equals(BatchRecognizeResponse, a, b);
  }
}

/**
 * Output type for Cloud Storage of BatchRecognize transcripts. Though this
 * proto isn't returned in this API anywhere, the Cloud Storage transcripts will
 * be this proto serialized and should be parsed as such.
 *
 * @generated from message google.cloud.speech.v2.BatchRecognizeResults
 */
export class BatchRecognizeResults extends Message<BatchRecognizeResults> {
  /**
   * Sequential list of transcription results corresponding to sequential
   * portions of audio.
   *
   * @generated from field: repeated google.cloud.speech.v2.SpeechRecognitionResult results = 1;
   */
  results: SpeechRecognitionResult[] = [];

  /**
   * Metadata about the recognition.
   *
   * @generated from field: google.cloud.speech.v2.RecognitionResponseMetadata metadata = 2;
   */
  metadata?: RecognitionResponseMetadata;

  constructor(data?: PartialMessage<BatchRecognizeResults>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.speech.v2.BatchRecognizeResults";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "results", kind: "message", T: SpeechRecognitionResult, repeated: true },
    { no: 2, name: "metadata", kind: "message", T: RecognitionResponseMetadata },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): BatchRecognizeResults {
    return new BatchRecognizeResults().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): BatchRecognizeResults {
    return new BatchRecognizeResults().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): BatchRecognizeResults {
    return new BatchRecognizeResults().fromJsonString(jsonString, options);
  }

  static equals(a: BatchRecognizeResults | PlainMessage<BatchRecognizeResults> | undefined, b: BatchRecognizeResults | PlainMessage<BatchRecognizeResults> | undefined): boolean {
    return proto3.util.equals(BatchRecognizeResults, a, b);
  }
}

/**
 * Final results for a single file.
 *
 * @generated from message google.cloud.speech.v2.BatchRecognizeFileResult
 */
export class BatchRecognizeFileResult extends Message<BatchRecognizeFileResult> {
  /**
   * The Cloud Storage URI to which recognition results were written.
   *
   * @generated from field: string uri = 1;
   */
  uri = "";

  /**
   * Error if one was encountered.
   *
   * @generated from field: google.rpc.Status error = 2;
   */
  error?: Status;

  /**
   * @generated from field: google.cloud.speech.v2.RecognitionResponseMetadata metadata = 3;
   */
  metadata?: RecognitionResponseMetadata;

  /**
   * The transcript for the audio file. This is populated only when
   * [InlineOutputConfig][google.cloud.speech.v2.InlineOutputConfig] is set in
   * the
   * [RecognitionOutputConfig][[google.cloud.speech.v2.RecognitionOutputConfig].
   *
   * @generated from field: google.cloud.speech.v2.BatchRecognizeResults transcript = 4;
   */
  transcript?: BatchRecognizeResults;

  constructor(data?: PartialMessage<BatchRecognizeFileResult>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.speech.v2.BatchRecognizeFileResult";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "uri", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "error", kind: "message", T: Status },
    { no: 3, name: "metadata", kind: "message", T: RecognitionResponseMetadata },
    { no: 4, name: "transcript", kind: "message", T: BatchRecognizeResults },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): BatchRecognizeFileResult {
    return new BatchRecognizeFileResult().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): BatchRecognizeFileResult {
    return new BatchRecognizeFileResult().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): BatchRecognizeFileResult {
    return new BatchRecognizeFileResult().fromJsonString(jsonString, options);
  }

  static equals(a: BatchRecognizeFileResult | PlainMessage<BatchRecognizeFileResult> | undefined, b: BatchRecognizeFileResult | PlainMessage<BatchRecognizeFileResult> | undefined): boolean {
    return proto3.util.equals(BatchRecognizeFileResult, a, b);
  }
}

/**
 * Metadata about transcription for a single file (for example, progress
 * percent).
 *
 * @generated from message google.cloud.speech.v2.BatchRecognizeTranscriptionMetadata
 */
export class BatchRecognizeTranscriptionMetadata extends Message<BatchRecognizeTranscriptionMetadata> {
  /**
   * How much of the file has been transcribed so far.
   *
   * @generated from field: int32 progress_percent = 1;
   */
  progressPercent = 0;

  /**
   * Error if one was encountered.
   *
   * @generated from field: google.rpc.Status error = 2;
   */
  error?: Status;

  /**
   * The Cloud Storage URI to which recognition results will be written.
   *
   * @generated from field: string uri = 3;
   */
  uri = "";

  constructor(data?: PartialMessage<BatchRecognizeTranscriptionMetadata>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.speech.v2.BatchRecognizeTranscriptionMetadata";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "progress_percent", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 2, name: "error", kind: "message", T: Status },
    { no: 3, name: "uri", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): BatchRecognizeTranscriptionMetadata {
    return new BatchRecognizeTranscriptionMetadata().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): BatchRecognizeTranscriptionMetadata {
    return new BatchRecognizeTranscriptionMetadata().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): BatchRecognizeTranscriptionMetadata {
    return new BatchRecognizeTranscriptionMetadata().fromJsonString(jsonString, options);
  }

  static equals(a: BatchRecognizeTranscriptionMetadata | PlainMessage<BatchRecognizeTranscriptionMetadata> | undefined, b: BatchRecognizeTranscriptionMetadata | PlainMessage<BatchRecognizeTranscriptionMetadata> | undefined): boolean {
    return proto3.util.equals(BatchRecognizeTranscriptionMetadata, a, b);
  }
}

/**
 * Operation metadata for
 * [BatchRecognize][google.cloud.speech.v2.Speech.BatchRecognize].
 *
 * @generated from message google.cloud.speech.v2.BatchRecognizeMetadata
 */
export class BatchRecognizeMetadata extends Message<BatchRecognizeMetadata> {
  /**
   * Map from provided filename to the transcription metadata for that file.
   *
   * @generated from field: map<string, google.cloud.speech.v2.BatchRecognizeTranscriptionMetadata> transcription_metadata = 1;
   */
  transcriptionMetadata: { [key: string]: BatchRecognizeTranscriptionMetadata } = {};

  constructor(data?: PartialMessage<BatchRecognizeMetadata>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.speech.v2.BatchRecognizeMetadata";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "transcription_metadata", kind: "map", K: 9 /* ScalarType.STRING */, V: {kind: "message", T: BatchRecognizeTranscriptionMetadata} },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): BatchRecognizeMetadata {
    return new BatchRecognizeMetadata().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): BatchRecognizeMetadata {
    return new BatchRecognizeMetadata().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): BatchRecognizeMetadata {
    return new BatchRecognizeMetadata().fromJsonString(jsonString, options);
  }

  static equals(a: BatchRecognizeMetadata | PlainMessage<BatchRecognizeMetadata> | undefined, b: BatchRecognizeMetadata | PlainMessage<BatchRecognizeMetadata> | undefined): boolean {
    return proto3.util.equals(BatchRecognizeMetadata, a, b);
  }
}

/**
 * Metadata about a single file in a batch for BatchRecognize.
 *
 * @generated from message google.cloud.speech.v2.BatchRecognizeFileMetadata
 */
export class BatchRecognizeFileMetadata extends Message<BatchRecognizeFileMetadata> {
  /**
   * The audio source, which is a Google Cloud Storage URI.
   *
   * @generated from oneof google.cloud.speech.v2.BatchRecognizeFileMetadata.audio_source
   */
  audioSource: {
    /**
     * Cloud Storage URI for the audio file.
     *
     * @generated from field: string uri = 1;
     */
    value: string;
    case: "uri";
  } | { case: undefined; value?: undefined } = { case: undefined };

  /**
   * Features and audio metadata to use for the Automatic Speech Recognition.
   * This field in combination with the
   * [config_mask][google.cloud.speech.v2.BatchRecognizeFileMetadata.config_mask]
   * field can be used to override parts of the
   * [default_recognition_config][google.cloud.speech.v2.Recognizer.default_recognition_config]
   * of the Recognizer resource as well as the
   * [config][google.cloud.speech.v2.BatchRecognizeRequest.config] at the
   * request level.
   *
   * @generated from field: google.cloud.speech.v2.RecognitionConfig config = 4;
   */
  config?: RecognitionConfig;

  /**
   * The list of fields in
   * [config][google.cloud.speech.v2.BatchRecognizeFileMetadata.config] that
   * override the values in the
   * [default_recognition_config][google.cloud.speech.v2.Recognizer.default_recognition_config]
   * of the recognizer during this recognition request. If no mask is provided,
   * all non-default valued fields in
   * [config][google.cloud.speech.v2.BatchRecognizeFileMetadata.config] override
   * the values in the recognizer for this recognition request. If a mask is
   * provided, only the fields listed in the mask override the config in the
   * recognizer for this recognition request. If a wildcard (`*`) is provided,
   * [config][google.cloud.speech.v2.BatchRecognizeFileMetadata.config]
   * completely overrides and replaces the config in the recognizer for this
   * recognition request.
   *
   * @generated from field: google.protobuf.FieldMask config_mask = 5;
   */
  configMask?: FieldMask;

  constructor(data?: PartialMessage<BatchRecognizeFileMetadata>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.speech.v2.BatchRecognizeFileMetadata";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "uri", kind: "scalar", T: 9 /* ScalarType.STRING */, oneof: "audio_source" },
    { no: 4, name: "config", kind: "message", T: RecognitionConfig },
    { no: 5, name: "config_mask", kind: "message", T: FieldMask },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): BatchRecognizeFileMetadata {
    return new BatchRecognizeFileMetadata().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): BatchRecognizeFileMetadata {
    return new BatchRecognizeFileMetadata().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): BatchRecognizeFileMetadata {
    return new BatchRecognizeFileMetadata().fromJsonString(jsonString, options);
  }

  static equals(a: BatchRecognizeFileMetadata | PlainMessage<BatchRecognizeFileMetadata> | undefined, b: BatchRecognizeFileMetadata | PlainMessage<BatchRecognizeFileMetadata> | undefined): boolean {
    return proto3.util.equals(BatchRecognizeFileMetadata, a, b);
  }
}

/**
 * A streaming speech recognition result corresponding to a portion of the audio
 * that is currently being processed.
 *
 * @generated from message google.cloud.speech.v2.StreamingRecognitionResult
 */
export class StreamingRecognitionResult extends Message<StreamingRecognitionResult> {
  /**
   * May contain one or more recognition hypotheses. These alternatives are
   * ordered in terms of accuracy, with the top (first) alternative being the
   * most probable, as ranked by the recognizer.
   *
   * @generated from field: repeated google.cloud.speech.v2.SpeechRecognitionAlternative alternatives = 1;
   */
  alternatives: SpeechRecognitionAlternative[] = [];

  /**
   * If `false`, this
   * [StreamingRecognitionResult][google.cloud.speech.v2.StreamingRecognitionResult]
   * represents an interim result that may change. If `true`, this is the final
   * time the speech service will return this particular
   * [StreamingRecognitionResult][google.cloud.speech.v2.StreamingRecognitionResult],
   * the recognizer will not return any further hypotheses for this portion of
   * the transcript and corresponding audio.
   *
   * @generated from field: bool is_final = 2;
   */
  isFinal = false;

  /**
   * An estimate of the likelihood that the recognizer will not change its guess
   * about this interim result. Values range from 0.0 (completely unstable)
   * to 1.0 (completely stable). This field is only provided for interim results
   * ([is_final][google.cloud.speech.v2.StreamingRecognitionResult.is_final]=`false`).
   * The default of 0.0 is a sentinel value indicating `stability` was not set.
   *
   * @generated from field: float stability = 3;
   */
  stability = 0;

  /**
   * Time offset of the end of this result relative to the beginning of the
   * audio.
   *
   * @generated from field: google.protobuf.Duration result_end_offset = 4;
   */
  resultEndOffset?: Duration;

  /**
   * For multi-channel audio, this is the channel number corresponding to the
   * recognized result for the audio from that channel.
   * For
   * `audio_channel_count` = `N`, its output values can range from `1` to `N`.
   *
   * @generated from field: int32 channel_tag = 5;
   */
  channelTag = 0;

  /**
   * Output only. The [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt)
   * language tag of the language in this result. This language code was
   * detected to have the most likelihood of being spoken in the audio.
   *
   * @generated from field: string language_code = 6;
   */
  languageCode = "";

  constructor(data?: PartialMessage<StreamingRecognitionResult>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.speech.v2.StreamingRecognitionResult";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "alternatives", kind: "message", T: SpeechRecognitionAlternative, repeated: true },
    { no: 2, name: "is_final", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
    { no: 3, name: "stability", kind: "scalar", T: 2 /* ScalarType.FLOAT */ },
    { no: 4, name: "result_end_offset", kind: "message", T: Duration },
    { no: 5, name: "channel_tag", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 6, name: "language_code", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): StreamingRecognitionResult {
    return new StreamingRecognitionResult().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): StreamingRecognitionResult {
    return new StreamingRecognitionResult().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): StreamingRecognitionResult {
    return new StreamingRecognitionResult().fromJsonString(jsonString, options);
  }

  static equals(a: StreamingRecognitionResult | PlainMessage<StreamingRecognitionResult> | undefined, b: StreamingRecognitionResult | PlainMessage<StreamingRecognitionResult> | undefined): boolean {
    return proto3.util.equals(StreamingRecognitionResult, a, b);
  }
}

/**
 * `StreamingRecognizeResponse` is the only message returned to the client by
 * `StreamingRecognize`. A series of zero or more `StreamingRecognizeResponse`
 * messages are streamed back to the client. If there is no recognizable
 * audio then no messages are streamed back to the client.
 *
 * Here are some examples of `StreamingRecognizeResponse`s that might
 * be returned while processing audio:
 *
 * 1. results { alternatives { transcript: "tube" } stability: 0.01 }
 *
 * 2. results { alternatives { transcript: "to be a" } stability: 0.01 }
 *
 * 3. results { alternatives { transcript: "to be" } stability: 0.9 }
 *    results { alternatives { transcript: " or not to be" } stability: 0.01 }
 *
 * 4. results { alternatives { transcript: "to be or not to be"
 *                             confidence: 0.92 }
 *              alternatives { transcript: "to bee or not to bee" }
 *              is_final: true }
 *
 * 5. results { alternatives { transcript: " that's" } stability: 0.01 }
 *
 * 6. results { alternatives { transcript: " that is" } stability: 0.9 }
 *    results { alternatives { transcript: " the question" } stability: 0.01 }
 *
 * 7. results { alternatives { transcript: " that is the question"
 *                             confidence: 0.98 }
 *              alternatives { transcript: " that was the question" }
 *              is_final: true }
 *
 * Notes:
 *
 * - Only two of the above responses #4 and #7 contain final results; they are
 *   indicated by `is_final: true`. Concatenating these together generates the
 *   full transcript: "to be or not to be that is the question".
 *
 * - The others contain interim `results`. #3 and #6 contain two interim
 *   `results`: the first portion has a high stability and is less likely to
 *   change; the second portion has a low stability and is very likely to
 *   change. A UI designer might choose to show only high stability `results`.
 *
 * - The specific `stability` and `confidence` values shown above are only for
 *   illustrative purposes. Actual values may vary.
 *
 * - In each response, only one of these fields will be set:
 *     `error`,
 *     `speech_event_type`, or
 *     one or more (repeated) `results`.
 *
 * @generated from message google.cloud.speech.v2.StreamingRecognizeResponse
 */
export class StreamingRecognizeResponse extends Message<StreamingRecognizeResponse> {
  /**
   * This repeated list contains zero or more results that
   * correspond to consecutive portions of the audio currently being processed.
   * It contains zero or one
   * [is_final][google.cloud.speech.v2.StreamingRecognitionResult.is_final]=`true`
   * result (the newly settled portion), followed by zero or more
   * [is_final][google.cloud.speech.v2.StreamingRecognitionResult.is_final]=`false`
   * results (the interim results).
   *
   * @generated from field: repeated google.cloud.speech.v2.StreamingRecognitionResult results = 6;
   */
  results: StreamingRecognitionResult[] = [];

  /**
   * Indicates the type of speech event.
   *
   * @generated from field: google.cloud.speech.v2.StreamingRecognizeResponse.SpeechEventType speech_event_type = 3;
   */
  speechEventType = StreamingRecognizeResponse_SpeechEventType.SPEECH_EVENT_TYPE_UNSPECIFIED;

  /**
   * Time offset between the beginning of the audio and event emission.
   *
   * @generated from field: google.protobuf.Duration speech_event_offset = 7;
   */
  speechEventOffset?: Duration;

  /**
   * Metadata about the recognition.
   *
   * @generated from field: google.cloud.speech.v2.RecognitionResponseMetadata metadata = 5;
   */
  metadata?: RecognitionResponseMetadata;

  constructor(data?: PartialMessage<StreamingRecognizeResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.speech.v2.StreamingRecognizeResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 6, name: "results", kind: "message", T: StreamingRecognitionResult, repeated: true },
    { no: 3, name: "speech_event_type", kind: "enum", T: proto3.getEnumType(StreamingRecognizeResponse_SpeechEventType) },
    { no: 7, name: "speech_event_offset", kind: "message", T: Duration },
    { no: 5, name: "metadata", kind: "message", T: RecognitionResponseMetadata },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): StreamingRecognizeResponse {
    return new StreamingRecognizeResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): StreamingRecognizeResponse {
    return new StreamingRecognizeResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): StreamingRecognizeResponse {
    return new StreamingRecognizeResponse().fromJsonString(jsonString, options);
  }

  static equals(a: StreamingRecognizeResponse | PlainMessage<StreamingRecognizeResponse> | undefined, b: StreamingRecognizeResponse | PlainMessage<StreamingRecognizeResponse> | undefined): boolean {
    return proto3.util.equals(StreamingRecognizeResponse, a, b);
  }
}

/**
 * Indicates the type of speech event.
 *
 * @generated from enum google.cloud.speech.v2.StreamingRecognizeResponse.SpeechEventType
 */
export enum StreamingRecognizeResponse_SpeechEventType {
  /**
   * No speech event specified.
   *
   * @generated from enum value: SPEECH_EVENT_TYPE_UNSPECIFIED = 0;
   */
  SPEECH_EVENT_TYPE_UNSPECIFIED = 0,

  /**
   * This event indicates that the server has detected the end of the user's
   * speech utterance and expects no additional speech. Therefore, the server
   * will not process additional audio and will close the gRPC bidirectional
   * stream. This event is only sent if there was a force cutoff due to
   * silence being detected early. This event is only available through the
   * `latest_short` [model][google.cloud.speech.v2.Recognizer.model].
   *
   * @generated from enum value: END_OF_SINGLE_UTTERANCE = 1;
   */
  END_OF_SINGLE_UTTERANCE = 1,

  /**
   * This event indicates that the server has detected the beginning of human
   * voice activity in the stream. This event can be returned multiple times
   * if speech starts and stops repeatedly throughout the stream. This event
   * is only sent if `voice_activity_events` is set to true.
   *
   * @generated from enum value: SPEECH_ACTIVITY_BEGIN = 2;
   */
  SPEECH_ACTIVITY_BEGIN = 2,

  /**
   * This event indicates that the server has detected the end of human voice
   * activity in the stream. This event can be returned multiple times if
   * speech starts and stops repeatedly throughout the stream. This event is
   * only sent if `voice_activity_events` is set to true.
   *
   * @generated from enum value: SPEECH_ACTIVITY_END = 3;
   */
  SPEECH_ACTIVITY_END = 3,
}
// Retrieve enum metadata with: proto3.getEnumType(StreamingRecognizeResponse_SpeechEventType)
proto3.util.setEnumType(StreamingRecognizeResponse_SpeechEventType, "google.cloud.speech.v2.StreamingRecognizeResponse.SpeechEventType", [
  { no: 0, name: "SPEECH_EVENT_TYPE_UNSPECIFIED" },
  { no: 1, name: "END_OF_SINGLE_UTTERANCE" },
  { no: 2, name: "SPEECH_ACTIVITY_BEGIN" },
  { no: 3, name: "SPEECH_ACTIVITY_END" },
]);

/**
 * Message representing the config for the Speech-to-Text API. This includes an
 * optional [KMS key](https://cloud.google.com/kms/docs/resource-hierarchy#keys)
 * with which incoming data will be encrypted.
 *
 * @generated from message google.cloud.speech.v2.Config
 */
export class Config extends Message<Config> {
  /**
   * Output only. The name of the config resource. There is exactly one config
   * resource per project per location. The expected format is
   * `projects/{project}/locations/{location}/config`.
   *
   * @generated from field: string name = 1;
   */
  name = "";

  /**
   * Optional. An optional [KMS key
   * name](https://cloud.google.com/kms/docs/resource-hierarchy#keys) that if
   * present, will be used to encrypt Speech-to-Text resources at-rest. Updating
   * this key will not encrypt existing resources using this key; only new
   * resources will be encrypted using this key. The expected format is
   * `projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}`.
   *
   * @generated from field: string kms_key_name = 2;
   */
  kmsKeyName = "";

  /**
   * Output only. The most recent time this resource was modified.
   *
   * @generated from field: google.protobuf.Timestamp update_time = 3;
   */
  updateTime?: Timestamp;

  constructor(data?: PartialMessage<Config>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.speech.v2.Config";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "name", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "kms_key_name", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 3, name: "update_time", kind: "message", T: Timestamp },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): Config {
    return new Config().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): Config {
    return new Config().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): Config {
    return new Config().fromJsonString(jsonString, options);
  }

  static equals(a: Config | PlainMessage<Config> | undefined, b: Config | PlainMessage<Config> | undefined): boolean {
    return proto3.util.equals(Config, a, b);
  }
}

/**
 * Request message for the
 * [GetConfig][google.cloud.speech.v2.Speech.GetConfig] method.
 *
 * @generated from message google.cloud.speech.v2.GetConfigRequest
 */
export class GetConfigRequest extends Message<GetConfigRequest> {
  /**
   * Required. The name of the config to retrieve. There is exactly one config
   * resource per project per location. The expected format is
   * `projects/{project}/locations/{location}/config`.
   *
   * @generated from field: string name = 1;
   */
  name = "";

  constructor(data?: PartialMessage<GetConfigRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.speech.v2.GetConfigRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "name", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): GetConfigRequest {
    return new GetConfigRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): GetConfigRequest {
    return new GetConfigRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): GetConfigRequest {
    return new GetConfigRequest().fromJsonString(jsonString, options);
  }

  static equals(a: GetConfigRequest | PlainMessage<GetConfigRequest> | undefined, b: GetConfigRequest | PlainMessage<GetConfigRequest> | undefined): boolean {
    return proto3.util.equals(GetConfigRequest, a, b);
  }
}

/**
 * Request message for the
 * [UpdateConfig][google.cloud.speech.v2.Speech.UpdateConfig] method.
 *
 * @generated from message google.cloud.speech.v2.UpdateConfigRequest
 */
export class UpdateConfigRequest extends Message<UpdateConfigRequest> {
  /**
   * Required. The config to update.
   *
   * The config's `name` field is used to identify the config to be updated.
   * The expected format is `projects/{project}/locations/{location}/config`.
   *
   * @generated from field: google.cloud.speech.v2.Config config = 1;
   */
  config?: Config;

  /**
   * The list of fields to be updated.
   *
   * @generated from field: google.protobuf.FieldMask update_mask = 2;
   */
  updateMask?: FieldMask;

  constructor(data?: PartialMessage<UpdateConfigRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.speech.v2.UpdateConfigRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "config", kind: "message", T: Config },
    { no: 2, name: "update_mask", kind: "message", T: FieldMask },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): UpdateConfigRequest {
    return new UpdateConfigRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): UpdateConfigRequest {
    return new UpdateConfigRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): UpdateConfigRequest {
    return new UpdateConfigRequest().fromJsonString(jsonString, options);
  }

  static equals(a: UpdateConfigRequest | PlainMessage<UpdateConfigRequest> | undefined, b: UpdateConfigRequest | PlainMessage<UpdateConfigRequest> | undefined): boolean {
    return proto3.util.equals(UpdateConfigRequest, a, b);
  }
}

/**
 * CustomClass for biasing in speech recognition. Used to define a set of words
 * or phrases that represents a common concept or theme likely to appear in your
 * audio, for example a list of passenger ship names.
 *
 * @generated from message google.cloud.speech.v2.CustomClass
 */
export class CustomClass extends Message<CustomClass> {
  /**
   * Output only. The resource name of the CustomClass.
   * Format:
   * `projects/{project}/locations/{location}/customClasses/{custom_class}`.
   *
   * @generated from field: string name = 1;
   */
  name = "";

  /**
   * Output only. System-assigned unique identifier for the CustomClass.
   *
   * @generated from field: string uid = 2;
   */
  uid = "";

  /**
   * User-settable, human-readable name for the CustomClass. Must be 63
   * characters or less.
   *
   * @generated from field: string display_name = 4;
   */
  displayName = "";

  /**
   * A collection of class items.
   *
   * @generated from field: repeated google.cloud.speech.v2.CustomClass.ClassItem items = 5;
   */
  items: CustomClass_ClassItem[] = [];

  /**
   * Output only. The CustomClass lifecycle state.
   *
   * @generated from field: google.cloud.speech.v2.CustomClass.State state = 15;
   */
  state = CustomClass_State.STATE_UNSPECIFIED;

  /**
   * Output only. Creation time.
   *
   * @generated from field: google.protobuf.Timestamp create_time = 6;
   */
  createTime?: Timestamp;

  /**
   * Output only. The most recent time this resource was modified.
   *
   * @generated from field: google.protobuf.Timestamp update_time = 7;
   */
  updateTime?: Timestamp;

  /**
   * Output only. The time at which this resource was requested for deletion.
   *
   * @generated from field: google.protobuf.Timestamp delete_time = 8;
   */
  deleteTime?: Timestamp;

  /**
   * Output only. The time at which this resource will be purged.
   *
   * @generated from field: google.protobuf.Timestamp expire_time = 9;
   */
  expireTime?: Timestamp;

  /**
   * Allows users to store small amounts of arbitrary data.
   * Both the key and the value must be 63 characters or less each.
   * At most 100 annotations.
   *
   * @generated from field: map<string, string> annotations = 10;
   */
  annotations: { [key: string]: string } = {};

  /**
   * Output only. This checksum is computed by the server based on the value of
   * other fields. This may be sent on update, undelete, and delete requests to
   * ensure the client has an up-to-date value before proceeding.
   *
   * @generated from field: string etag = 11;
   */
  etag = "";

  /**
   * Output only. Whether or not this CustomClass is in the process of being
   * updated.
   *
   * @generated from field: bool reconciling = 12;
   */
  reconciling = false;

  /**
   * Output only. The [KMS key
   * name](https://cloud.google.com/kms/docs/resource-hierarchy#keys) with which
   * the CustomClass is encrypted. The expected format is
   * `projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}`.
   *
   * @generated from field: string kms_key_name = 13;
   */
  kmsKeyName = "";

  /**
   * Output only. The [KMS key version
   * name](https://cloud.google.com/kms/docs/resource-hierarchy#key_versions)
   * with which the CustomClass is encrypted. The expected format is
   * `projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}/cryptoKeyVersions/{crypto_key_version}`.
   *
   * @generated from field: string kms_key_version_name = 14;
   */
  kmsKeyVersionName = "";

  constructor(data?: PartialMessage<CustomClass>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.speech.v2.CustomClass";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "name", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "uid", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 4, name: "display_name", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 5, name: "items", kind: "message", T: CustomClass_ClassItem, repeated: true },
    { no: 15, name: "state", kind: "enum", T: proto3.getEnumType(CustomClass_State) },
    { no: 6, name: "create_time", kind: "message", T: Timestamp },
    { no: 7, name: "update_time", kind: "message", T: Timestamp },
    { no: 8, name: "delete_time", kind: "message", T: Timestamp },
    { no: 9, name: "expire_time", kind: "message", T: Timestamp },
    { no: 10, name: "annotations", kind: "map", K: 9 /* ScalarType.STRING */, V: {kind: "scalar", T: 9 /* ScalarType.STRING */} },
    { no: 11, name: "etag", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 12, name: "reconciling", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
    { no: 13, name: "kms_key_name", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 14, name: "kms_key_version_name", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): CustomClass {
    return new CustomClass().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): CustomClass {
    return new CustomClass().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): CustomClass {
    return new CustomClass().fromJsonString(jsonString, options);
  }

  static equals(a: CustomClass | PlainMessage<CustomClass> | undefined, b: CustomClass | PlainMessage<CustomClass> | undefined): boolean {
    return proto3.util.equals(CustomClass, a, b);
  }
}

/**
 * Set of states that define the lifecycle of a CustomClass.
 *
 * @generated from enum google.cloud.speech.v2.CustomClass.State
 */
export enum CustomClass_State {
  /**
   * Unspecified state.  This is only used/useful for distinguishing
   * unset values.
   *
   * @generated from enum value: STATE_UNSPECIFIED = 0;
   */
  STATE_UNSPECIFIED = 0,

  /**
   * The normal and active state.
   *
   * @generated from enum value: ACTIVE = 2;
   */
  ACTIVE = 2,

  /**
   * This CustomClass has been deleted.
   *
   * @generated from enum value: DELETED = 4;
   */
  DELETED = 4,
}
// Retrieve enum metadata with: proto3.getEnumType(CustomClass_State)
proto3.util.setEnumType(CustomClass_State, "google.cloud.speech.v2.CustomClass.State", [
  { no: 0, name: "STATE_UNSPECIFIED" },
  { no: 2, name: "ACTIVE" },
  { no: 4, name: "DELETED" },
]);

/**
 * An item of the class.
 *
 * @generated from message google.cloud.speech.v2.CustomClass.ClassItem
 */
export class CustomClass_ClassItem extends Message<CustomClass_ClassItem> {
  /**
   * The class item's value.
   *
   * @generated from field: string value = 1;
   */
  value = "";

  constructor(data?: PartialMessage<CustomClass_ClassItem>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.speech.v2.CustomClass.ClassItem";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "value", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): CustomClass_ClassItem {
    return new CustomClass_ClassItem().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): CustomClass_ClassItem {
    return new CustomClass_ClassItem().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): CustomClass_ClassItem {
    return new CustomClass_ClassItem().fromJsonString(jsonString, options);
  }

  static equals(a: CustomClass_ClassItem | PlainMessage<CustomClass_ClassItem> | undefined, b: CustomClass_ClassItem | PlainMessage<CustomClass_ClassItem> | undefined): boolean {
    return proto3.util.equals(CustomClass_ClassItem, a, b);
  }
}

/**
 * PhraseSet for biasing in speech recognition. A PhraseSet is used to provide
 * "hints" to the speech recognizer to favor specific words and phrases in the
 * results.
 *
 * @generated from message google.cloud.speech.v2.PhraseSet
 */
export class PhraseSet extends Message<PhraseSet> {
  /**
   * Output only. The resource name of the PhraseSet.
   * Format: `projects/{project}/locations/{location}/phraseSets/{phrase_set}`.
   *
   * @generated from field: string name = 1;
   */
  name = "";

  /**
   * Output only. System-assigned unique identifier for the PhraseSet.
   *
   * @generated from field: string uid = 2;
   */
  uid = "";

  /**
   * A list of word and phrases.
   *
   * @generated from field: repeated google.cloud.speech.v2.PhraseSet.Phrase phrases = 3;
   */
  phrases: PhraseSet_Phrase[] = [];

  /**
   * Hint Boost. Positive value will increase the probability that a specific
   * phrase will be recognized over other similar sounding phrases. The higher
   * the boost, the higher the chance of false positive recognition as well.
   * Valid `boost` values are between 0 (exclusive) and 20. We recommend using a
   * binary search approach to finding the optimal value for your use case as
   * well as adding phrases both with and without boost to your requests.
   *
   * @generated from field: float boost = 4;
   */
  boost = 0;

  /**
   * User-settable, human-readable name for the PhraseSet. Must be 63
   * characters or less.
   *
   * @generated from field: string display_name = 5;
   */
  displayName = "";

  /**
   * Output only. The PhraseSet lifecycle state.
   *
   * @generated from field: google.cloud.speech.v2.PhraseSet.State state = 15;
   */
  state = PhraseSet_State.STATE_UNSPECIFIED;

  /**
   * Output only. Creation time.
   *
   * @generated from field: google.protobuf.Timestamp create_time = 6;
   */
  createTime?: Timestamp;

  /**
   * Output only. The most recent time this resource was modified.
   *
   * @generated from field: google.protobuf.Timestamp update_time = 7;
   */
  updateTime?: Timestamp;

  /**
   * Output only. The time at which this resource was requested for deletion.
   *
   * @generated from field: google.protobuf.Timestamp delete_time = 8;
   */
  deleteTime?: Timestamp;

  /**
   * Output only. The time at which this resource will be purged.
   *
   * @generated from field: google.protobuf.Timestamp expire_time = 9;
   */
  expireTime?: Timestamp;

  /**
   * Allows users to store small amounts of arbitrary data.
   * Both the key and the value must be 63 characters or less each.
   * At most 100 annotations.
   *
   * @generated from field: map<string, string> annotations = 10;
   */
  annotations: { [key: string]: string } = {};

  /**
   * Output only. This checksum is computed by the server based on the value of
   * other fields. This may be sent on update, undelete, and delete requests to
   * ensure the client has an up-to-date value before proceeding.
   *
   * @generated from field: string etag = 11;
   */
  etag = "";

  /**
   * Output only. Whether or not this PhraseSet is in the process of being
   * updated.
   *
   * @generated from field: bool reconciling = 12;
   */
  reconciling = false;

  /**
   * Output only. The [KMS key
   * name](https://cloud.google.com/kms/docs/resource-hierarchy#keys) with which
   * the PhraseSet is encrypted. The expected format is
   * `projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}`.
   *
   * @generated from field: string kms_key_name = 13;
   */
  kmsKeyName = "";

  /**
   * Output only. The [KMS key version
   * name](https://cloud.google.com/kms/docs/resource-hierarchy#key_versions)
   * with which the PhraseSet is encrypted. The expected format is
   * `projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}/cryptoKeyVersions/{crypto_key_version}`.
   *
   * @generated from field: string kms_key_version_name = 14;
   */
  kmsKeyVersionName = "";

  constructor(data?: PartialMessage<PhraseSet>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.speech.v2.PhraseSet";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "name", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "uid", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 3, name: "phrases", kind: "message", T: PhraseSet_Phrase, repeated: true },
    { no: 4, name: "boost", kind: "scalar", T: 2 /* ScalarType.FLOAT */ },
    { no: 5, name: "display_name", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 15, name: "state", kind: "enum", T: proto3.getEnumType(PhraseSet_State) },
    { no: 6, name: "create_time", kind: "message", T: Timestamp },
    { no: 7, name: "update_time", kind: "message", T: Timestamp },
    { no: 8, name: "delete_time", kind: "message", T: Timestamp },
    { no: 9, name: "expire_time", kind: "message", T: Timestamp },
    { no: 10, name: "annotations", kind: "map", K: 9 /* ScalarType.STRING */, V: {kind: "scalar", T: 9 /* ScalarType.STRING */} },
    { no: 11, name: "etag", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 12, name: "reconciling", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
    { no: 13, name: "kms_key_name", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 14, name: "kms_key_version_name", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): PhraseSet {
    return new PhraseSet().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): PhraseSet {
    return new PhraseSet().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): PhraseSet {
    return new PhraseSet().fromJsonString(jsonString, options);
  }

  static equals(a: PhraseSet | PlainMessage<PhraseSet> | undefined, b: PhraseSet | PlainMessage<PhraseSet> | undefined): boolean {
    return proto3.util.equals(PhraseSet, a, b);
  }
}

/**
 * Set of states that define the lifecycle of a PhraseSet.
 *
 * @generated from enum google.cloud.speech.v2.PhraseSet.State
 */
export enum PhraseSet_State {
  /**
   * Unspecified state.  This is only used/useful for distinguishing
   * unset values.
   *
   * @generated from enum value: STATE_UNSPECIFIED = 0;
   */
  STATE_UNSPECIFIED = 0,

  /**
   * The normal and active state.
   *
   * @generated from enum value: ACTIVE = 2;
   */
  ACTIVE = 2,

  /**
   * This PhraseSet has been deleted.
   *
   * @generated from enum value: DELETED = 4;
   */
  DELETED = 4,
}
// Retrieve enum metadata with: proto3.getEnumType(PhraseSet_State)
proto3.util.setEnumType(PhraseSet_State, "google.cloud.speech.v2.PhraseSet.State", [
  { no: 0, name: "STATE_UNSPECIFIED" },
  { no: 2, name: "ACTIVE" },
  { no: 4, name: "DELETED" },
]);

/**
 * A Phrase contains words and phrase "hints" so that the speech recognition
 * is more likely to recognize them. This can be used to improve the accuracy
 * for specific words and phrases, for example, if specific commands are
 * typically spoken by the user. This can also be used to add additional words
 * to the vocabulary of the recognizer.
 *
 * List items can also include CustomClass references containing groups of
 * words that represent common concepts that occur in natural language.
 *
 * @generated from message google.cloud.speech.v2.PhraseSet.Phrase
 */
export class PhraseSet_Phrase extends Message<PhraseSet_Phrase> {
  /**
   * The phrase itself.
   *
   * @generated from field: string value = 1;
   */
  value = "";

  /**
   * Hint Boost. Overrides the boost set at the phrase set level.
   * Positive value will increase the probability that a specific phrase will
   * be recognized over other similar sounding phrases. The higher the boost,
   * the higher the chance of false positive recognition as well. Negative
   * boost values would correspond to anti-biasing. Anti-biasing is not
   * enabled, so negative boost values will return an error. Boost values must
   * be between 0 and 20. Any values outside that range will return an error.
   * We recommend using a binary search approach to finding the optimal value
   * for your use case as well as adding phrases both with and without boost
   * to your requests.
   *
   * @generated from field: float boost = 2;
   */
  boost = 0;

  constructor(data?: PartialMessage<PhraseSet_Phrase>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.speech.v2.PhraseSet.Phrase";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "value", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "boost", kind: "scalar", T: 2 /* ScalarType.FLOAT */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): PhraseSet_Phrase {
    return new PhraseSet_Phrase().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): PhraseSet_Phrase {
    return new PhraseSet_Phrase().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): PhraseSet_Phrase {
    return new PhraseSet_Phrase().fromJsonString(jsonString, options);
  }

  static equals(a: PhraseSet_Phrase | PlainMessage<PhraseSet_Phrase> | undefined, b: PhraseSet_Phrase | PlainMessage<PhraseSet_Phrase> | undefined): boolean {
    return proto3.util.equals(PhraseSet_Phrase, a, b);
  }
}

/**
 * Request message for the
 * [CreateCustomClass][google.cloud.speech.v2.Speech.CreateCustomClass] method.
 *
 * @generated from message google.cloud.speech.v2.CreateCustomClassRequest
 */
export class CreateCustomClassRequest extends Message<CreateCustomClassRequest> {
  /**
   * Required. The CustomClass to create.
   *
   * @generated from field: google.cloud.speech.v2.CustomClass custom_class = 1;
   */
  customClass?: CustomClass;

  /**
   * If set, validate the request and preview the CustomClass, but do not
   * actually create it.
   *
   * @generated from field: bool validate_only = 2;
   */
  validateOnly = false;

  /**
   * The ID to use for the CustomClass, which will become the final component of
   * the CustomClass's resource name.
   *
   * This value should be 4-63 characters, and valid characters
   * are /[a-z][0-9]-/.
   *
   * @generated from field: string custom_class_id = 3;
   */
  customClassId = "";

  /**
   * Required. The project and location where this CustomClass will be created.
   * The expected format is `projects/{project}/locations/{location}`.
   *
   * @generated from field: string parent = 4;
   */
  parent = "";

  constructor(data?: PartialMessage<CreateCustomClassRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.speech.v2.CreateCustomClassRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "custom_class", kind: "message", T: CustomClass },
    { no: 2, name: "validate_only", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
    { no: 3, name: "custom_class_id", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 4, name: "parent", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): CreateCustomClassRequest {
    return new CreateCustomClassRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): CreateCustomClassRequest {
    return new CreateCustomClassRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): CreateCustomClassRequest {
    return new CreateCustomClassRequest().fromJsonString(jsonString, options);
  }

  static equals(a: CreateCustomClassRequest | PlainMessage<CreateCustomClassRequest> | undefined, b: CreateCustomClassRequest | PlainMessage<CreateCustomClassRequest> | undefined): boolean {
    return proto3.util.equals(CreateCustomClassRequest, a, b);
  }
}

/**
 * Request message for the
 * [ListCustomClasses][google.cloud.speech.v2.Speech.ListCustomClasses] method.
 *
 * @generated from message google.cloud.speech.v2.ListCustomClassesRequest
 */
export class ListCustomClassesRequest extends Message<ListCustomClassesRequest> {
  /**
   * Required. The project and location of CustomClass resources to list. The
   * expected format is `projects/{project}/locations/{location}`.
   *
   * @generated from field: string parent = 1;
   */
  parent = "";

  /**
   * Number of results per requests. A valid page_size ranges from 0 to 20
   * inclusive. If the page_size is zero or unspecified, a page size of 5 will
   * be chosen. If the page size exceeds 20, it will be coerced down to 20. Note
   * that a call might return fewer results than the requested page size.
   *
   * @generated from field: int32 page_size = 2;
   */
  pageSize = 0;

  /**
   * A page token, received from a previous
   * [ListCustomClasses][google.cloud.speech.v2.Speech.ListCustomClasses] call.
   * Provide this to retrieve the subsequent page.
   *
   * When paginating, all other parameters provided to
   * [ListCustomClasses][google.cloud.speech.v2.Speech.ListCustomClasses] must
   * match the call that provided the page token.
   *
   * @generated from field: string page_token = 3;
   */
  pageToken = "";

  /**
   * Whether, or not, to show resources that have been deleted.
   *
   * @generated from field: bool show_deleted = 4;
   */
  showDeleted = false;

  constructor(data?: PartialMessage<ListCustomClassesRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.speech.v2.ListCustomClassesRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "parent", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "page_size", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 3, name: "page_token", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 4, name: "show_deleted", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ListCustomClassesRequest {
    return new ListCustomClassesRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ListCustomClassesRequest {
    return new ListCustomClassesRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ListCustomClassesRequest {
    return new ListCustomClassesRequest().fromJsonString(jsonString, options);
  }

  static equals(a: ListCustomClassesRequest | PlainMessage<ListCustomClassesRequest> | undefined, b: ListCustomClassesRequest | PlainMessage<ListCustomClassesRequest> | undefined): boolean {
    return proto3.util.equals(ListCustomClassesRequest, a, b);
  }
}

/**
 * Response message for the
 * [ListCustomClasses][google.cloud.speech.v2.Speech.ListCustomClasses] method.
 *
 * @generated from message google.cloud.speech.v2.ListCustomClassesResponse
 */
export class ListCustomClassesResponse extends Message<ListCustomClassesResponse> {
  /**
   * The list of requested CustomClasses.
   *
   * @generated from field: repeated google.cloud.speech.v2.CustomClass custom_classes = 1;
   */
  customClasses: CustomClass[] = [];

  /**
   * A token, which can be sent as
   * [page_token][google.cloud.speech.v2.ListCustomClassesRequest.page_token] to
   * retrieve the next page. If this field is omitted, there are no subsequent
   * pages. This token expires after 72 hours.
   *
   * @generated from field: string next_page_token = 2;
   */
  nextPageToken = "";

  constructor(data?: PartialMessage<ListCustomClassesResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.speech.v2.ListCustomClassesResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "custom_classes", kind: "message", T: CustomClass, repeated: true },
    { no: 2, name: "next_page_token", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ListCustomClassesResponse {
    return new ListCustomClassesResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ListCustomClassesResponse {
    return new ListCustomClassesResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ListCustomClassesResponse {
    return new ListCustomClassesResponse().fromJsonString(jsonString, options);
  }

  static equals(a: ListCustomClassesResponse | PlainMessage<ListCustomClassesResponse> | undefined, b: ListCustomClassesResponse | PlainMessage<ListCustomClassesResponse> | undefined): boolean {
    return proto3.util.equals(ListCustomClassesResponse, a, b);
  }
}

/**
 * Request message for the
 * [GetCustomClass][google.cloud.speech.v2.Speech.GetCustomClass] method.
 *
 * @generated from message google.cloud.speech.v2.GetCustomClassRequest
 */
export class GetCustomClassRequest extends Message<GetCustomClassRequest> {
  /**
   * Required. The name of the CustomClass to retrieve. The expected format is
   * `projects/{project}/locations/{location}/customClasses/{custom_class}`.
   *
   * @generated from field: string name = 1;
   */
  name = "";

  constructor(data?: PartialMessage<GetCustomClassRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.speech.v2.GetCustomClassRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "name", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): GetCustomClassRequest {
    return new GetCustomClassRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): GetCustomClassRequest {
    return new GetCustomClassRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): GetCustomClassRequest {
    return new GetCustomClassRequest().fromJsonString(jsonString, options);
  }

  static equals(a: GetCustomClassRequest | PlainMessage<GetCustomClassRequest> | undefined, b: GetCustomClassRequest | PlainMessage<GetCustomClassRequest> | undefined): boolean {
    return proto3.util.equals(GetCustomClassRequest, a, b);
  }
}

/**
 * Request message for the
 * [UpdateCustomClass][google.cloud.speech.v2.Speech.UpdateCustomClass] method.
 *
 * @generated from message google.cloud.speech.v2.UpdateCustomClassRequest
 */
export class UpdateCustomClassRequest extends Message<UpdateCustomClassRequest> {
  /**
   * Required. The CustomClass to update.
   *
   * The CustomClass's `name` field is used to identify the CustomClass to
   * update. Format:
   * `projects/{project}/locations/{location}/customClasses/{custom_class}`.
   *
   * @generated from field: google.cloud.speech.v2.CustomClass custom_class = 1;
   */
  customClass?: CustomClass;

  /**
   * The list of fields to be updated. If empty, all fields are considered for
   * update.
   *
   * @generated from field: google.protobuf.FieldMask update_mask = 2;
   */
  updateMask?: FieldMask;

  /**
   * If set, validate the request and preview the updated CustomClass, but do
   * not actually update it.
   *
   * @generated from field: bool validate_only = 4;
   */
  validateOnly = false;

  constructor(data?: PartialMessage<UpdateCustomClassRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.speech.v2.UpdateCustomClassRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "custom_class", kind: "message", T: CustomClass },
    { no: 2, name: "update_mask", kind: "message", T: FieldMask },
    { no: 4, name: "validate_only", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): UpdateCustomClassRequest {
    return new UpdateCustomClassRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): UpdateCustomClassRequest {
    return new UpdateCustomClassRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): UpdateCustomClassRequest {
    return new UpdateCustomClassRequest().fromJsonString(jsonString, options);
  }

  static equals(a: UpdateCustomClassRequest | PlainMessage<UpdateCustomClassRequest> | undefined, b: UpdateCustomClassRequest | PlainMessage<UpdateCustomClassRequest> | undefined): boolean {
    return proto3.util.equals(UpdateCustomClassRequest, a, b);
  }
}

/**
 * Request message for the
 * [DeleteCustomClass][google.cloud.speech.v2.Speech.DeleteCustomClass] method.
 *
 * @generated from message google.cloud.speech.v2.DeleteCustomClassRequest
 */
export class DeleteCustomClassRequest extends Message<DeleteCustomClassRequest> {
  /**
   * Required. The name of the CustomClass to delete.
   * Format:
   * `projects/{project}/locations/{location}/customClasses/{custom_class}`
   *
   * @generated from field: string name = 1;
   */
  name = "";

  /**
   * If set, validate the request and preview the deleted CustomClass, but do
   * not actually delete it.
   *
   * @generated from field: bool validate_only = 2;
   */
  validateOnly = false;

  /**
   * If set to true, and the CustomClass is not found, the request will succeed
   * and  be a no-op (no Operation is recorded in this case).
   *
   * @generated from field: bool allow_missing = 4;
   */
  allowMissing = false;

  /**
   * This checksum is computed by the server based on the value of other
   * fields. This may be sent on update, undelete, and delete requests to ensure
   * the client has an up-to-date value before proceeding.
   *
   * @generated from field: string etag = 3;
   */
  etag = "";

  constructor(data?: PartialMessage<DeleteCustomClassRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.speech.v2.DeleteCustomClassRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "name", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "validate_only", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
    { no: 4, name: "allow_missing", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
    { no: 3, name: "etag", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): DeleteCustomClassRequest {
    return new DeleteCustomClassRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): DeleteCustomClassRequest {
    return new DeleteCustomClassRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): DeleteCustomClassRequest {
    return new DeleteCustomClassRequest().fromJsonString(jsonString, options);
  }

  static equals(a: DeleteCustomClassRequest | PlainMessage<DeleteCustomClassRequest> | undefined, b: DeleteCustomClassRequest | PlainMessage<DeleteCustomClassRequest> | undefined): boolean {
    return proto3.util.equals(DeleteCustomClassRequest, a, b);
  }
}

/**
 * Request message for the
 * [UndeleteCustomClass][google.cloud.speech.v2.Speech.UndeleteCustomClass]
 * method.
 *
 * @generated from message google.cloud.speech.v2.UndeleteCustomClassRequest
 */
export class UndeleteCustomClassRequest extends Message<UndeleteCustomClassRequest> {
  /**
   * Required. The name of the CustomClass to undelete.
   * Format:
   * `projects/{project}/locations/{location}/customClasses/{custom_class}`
   *
   * @generated from field: string name = 1;
   */
  name = "";

  /**
   * If set, validate the request and preview the undeleted CustomClass, but do
   * not actually undelete it.
   *
   * @generated from field: bool validate_only = 3;
   */
  validateOnly = false;

  /**
   * This checksum is computed by the server based on the value of other
   * fields. This may be sent on update, undelete, and delete requests to ensure
   * the client has an up-to-date value before proceeding.
   *
   * @generated from field: string etag = 4;
   */
  etag = "";

  constructor(data?: PartialMessage<UndeleteCustomClassRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.speech.v2.UndeleteCustomClassRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "name", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 3, name: "validate_only", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
    { no: 4, name: "etag", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): UndeleteCustomClassRequest {
    return new UndeleteCustomClassRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): UndeleteCustomClassRequest {
    return new UndeleteCustomClassRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): UndeleteCustomClassRequest {
    return new UndeleteCustomClassRequest().fromJsonString(jsonString, options);
  }

  static equals(a: UndeleteCustomClassRequest | PlainMessage<UndeleteCustomClassRequest> | undefined, b: UndeleteCustomClassRequest | PlainMessage<UndeleteCustomClassRequest> | undefined): boolean {
    return proto3.util.equals(UndeleteCustomClassRequest, a, b);
  }
}

/**
 * Request message for the
 * [CreatePhraseSet][google.cloud.speech.v2.Speech.CreatePhraseSet] method.
 *
 * @generated from message google.cloud.speech.v2.CreatePhraseSetRequest
 */
export class CreatePhraseSetRequest extends Message<CreatePhraseSetRequest> {
  /**
   * Required. The PhraseSet to create.
   *
   * @generated from field: google.cloud.speech.v2.PhraseSet phrase_set = 1;
   */
  phraseSet?: PhraseSet;

  /**
   * If set, validate the request and preview the PhraseSet, but do not
   * actually create it.
   *
   * @generated from field: bool validate_only = 2;
   */
  validateOnly = false;

  /**
   * The ID to use for the PhraseSet, which will become the final component of
   * the PhraseSet's resource name.
   *
   * This value should be 4-63 characters, and valid characters
   * are /[a-z][0-9]-/.
   *
   * @generated from field: string phrase_set_id = 3;
   */
  phraseSetId = "";

  /**
   * Required. The project and location where this PhraseSet will be created.
   * The expected format is `projects/{project}/locations/{location}`.
   *
   * @generated from field: string parent = 4;
   */
  parent = "";

  constructor(data?: PartialMessage<CreatePhraseSetRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.speech.v2.CreatePhraseSetRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "phrase_set", kind: "message", T: PhraseSet },
    { no: 2, name: "validate_only", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
    { no: 3, name: "phrase_set_id", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 4, name: "parent", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): CreatePhraseSetRequest {
    return new CreatePhraseSetRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): CreatePhraseSetRequest {
    return new CreatePhraseSetRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): CreatePhraseSetRequest {
    return new CreatePhraseSetRequest().fromJsonString(jsonString, options);
  }

  static equals(a: CreatePhraseSetRequest | PlainMessage<CreatePhraseSetRequest> | undefined, b: CreatePhraseSetRequest | PlainMessage<CreatePhraseSetRequest> | undefined): boolean {
    return proto3.util.equals(CreatePhraseSetRequest, a, b);
  }
}

/**
 * Request message for the
 * [ListPhraseSets][google.cloud.speech.v2.Speech.ListPhraseSets] method.
 *
 * @generated from message google.cloud.speech.v2.ListPhraseSetsRequest
 */
export class ListPhraseSetsRequest extends Message<ListPhraseSetsRequest> {
  /**
   * Required. The project and location of PhraseSet resources to list. The
   * expected format is `projects/{project}/locations/{location}`.
   *
   * @generated from field: string parent = 1;
   */
  parent = "";

  /**
   * The maximum number of PhraseSets to return. The service may return fewer
   * than this value. If unspecified, at most 20 PhraseSets will be returned.
   * The maximum value is 20; values above 20 will be coerced to 20.
   *
   * @generated from field: int32 page_size = 2;
   */
  pageSize = 0;

  /**
   * A page token, received from a previous
   * [ListPhraseSets][google.cloud.speech.v2.Speech.ListPhraseSets] call.
   * Provide this to retrieve the subsequent page.
   *
   * When paginating, all other parameters provided to
   * [ListPhraseSets][google.cloud.speech.v2.Speech.ListPhraseSets] must match
   * the call that provided the page token.
   *
   * @generated from field: string page_token = 3;
   */
  pageToken = "";

  /**
   * Whether, or not, to show resources that have been deleted.
   *
   * @generated from field: bool show_deleted = 4;
   */
  showDeleted = false;

  constructor(data?: PartialMessage<ListPhraseSetsRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.speech.v2.ListPhraseSetsRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "parent", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "page_size", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 3, name: "page_token", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 4, name: "show_deleted", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ListPhraseSetsRequest {
    return new ListPhraseSetsRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ListPhraseSetsRequest {
    return new ListPhraseSetsRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ListPhraseSetsRequest {
    return new ListPhraseSetsRequest().fromJsonString(jsonString, options);
  }

  static equals(a: ListPhraseSetsRequest | PlainMessage<ListPhraseSetsRequest> | undefined, b: ListPhraseSetsRequest | PlainMessage<ListPhraseSetsRequest> | undefined): boolean {
    return proto3.util.equals(ListPhraseSetsRequest, a, b);
  }
}

/**
 * Response message for the
 * [ListPhraseSets][google.cloud.speech.v2.Speech.ListPhraseSets] method.
 *
 * @generated from message google.cloud.speech.v2.ListPhraseSetsResponse
 */
export class ListPhraseSetsResponse extends Message<ListPhraseSetsResponse> {
  /**
   * The list of requested PhraseSets.
   *
   * @generated from field: repeated google.cloud.speech.v2.PhraseSet phrase_sets = 1;
   */
  phraseSets: PhraseSet[] = [];

  /**
   * A token, which can be sent as
   * [page_token][google.cloud.speech.v2.ListPhraseSetsRequest.page_token] to
   * retrieve the next page. If this field is omitted, there are no subsequent
   * pages. This token expires after 72 hours.
   *
   * @generated from field: string next_page_token = 2;
   */
  nextPageToken = "";

  constructor(data?: PartialMessage<ListPhraseSetsResponse>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.speech.v2.ListPhraseSetsResponse";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "phrase_sets", kind: "message", T: PhraseSet, repeated: true },
    { no: 2, name: "next_page_token", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): ListPhraseSetsResponse {
    return new ListPhraseSetsResponse().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): ListPhraseSetsResponse {
    return new ListPhraseSetsResponse().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): ListPhraseSetsResponse {
    return new ListPhraseSetsResponse().fromJsonString(jsonString, options);
  }

  static equals(a: ListPhraseSetsResponse | PlainMessage<ListPhraseSetsResponse> | undefined, b: ListPhraseSetsResponse | PlainMessage<ListPhraseSetsResponse> | undefined): boolean {
    return proto3.util.equals(ListPhraseSetsResponse, a, b);
  }
}

/**
 * Request message for the
 * [GetPhraseSet][google.cloud.speech.v2.Speech.GetPhraseSet] method.
 *
 * @generated from message google.cloud.speech.v2.GetPhraseSetRequest
 */
export class GetPhraseSetRequest extends Message<GetPhraseSetRequest> {
  /**
   * Required. The name of the PhraseSet to retrieve. The expected format is
   * `projects/{project}/locations/{location}/phraseSets/{phrase_set}`.
   *
   * @generated from field: string name = 1;
   */
  name = "";

  constructor(data?: PartialMessage<GetPhraseSetRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.speech.v2.GetPhraseSetRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "name", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): GetPhraseSetRequest {
    return new GetPhraseSetRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): GetPhraseSetRequest {
    return new GetPhraseSetRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): GetPhraseSetRequest {
    return new GetPhraseSetRequest().fromJsonString(jsonString, options);
  }

  static equals(a: GetPhraseSetRequest | PlainMessage<GetPhraseSetRequest> | undefined, b: GetPhraseSetRequest | PlainMessage<GetPhraseSetRequest> | undefined): boolean {
    return proto3.util.equals(GetPhraseSetRequest, a, b);
  }
}

/**
 * Request message for the
 * [UpdatePhraseSet][google.cloud.speech.v2.Speech.UpdatePhraseSet] method.
 *
 * @generated from message google.cloud.speech.v2.UpdatePhraseSetRequest
 */
export class UpdatePhraseSetRequest extends Message<UpdatePhraseSetRequest> {
  /**
   * Required. The PhraseSet to update.
   *
   * The PhraseSet's `name` field is used to identify the PhraseSet to update.
   * Format: `projects/{project}/locations/{location}/phraseSets/{phrase_set}`.
   *
   * @generated from field: google.cloud.speech.v2.PhraseSet phrase_set = 1;
   */
  phraseSet?: PhraseSet;

  /**
   * The list of fields to update. If empty, all non-default valued fields are
   * considered for update. Use `*` to update the entire PhraseSet resource.
   *
   * @generated from field: google.protobuf.FieldMask update_mask = 2;
   */
  updateMask?: FieldMask;

  /**
   * If set, validate the request and preview the updated PhraseSet, but do not
   * actually update it.
   *
   * @generated from field: bool validate_only = 4;
   */
  validateOnly = false;

  constructor(data?: PartialMessage<UpdatePhraseSetRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.speech.v2.UpdatePhraseSetRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "phrase_set", kind: "message", T: PhraseSet },
    { no: 2, name: "update_mask", kind: "message", T: FieldMask },
    { no: 4, name: "validate_only", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): UpdatePhraseSetRequest {
    return new UpdatePhraseSetRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): UpdatePhraseSetRequest {
    return new UpdatePhraseSetRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): UpdatePhraseSetRequest {
    return new UpdatePhraseSetRequest().fromJsonString(jsonString, options);
  }

  static equals(a: UpdatePhraseSetRequest | PlainMessage<UpdatePhraseSetRequest> | undefined, b: UpdatePhraseSetRequest | PlainMessage<UpdatePhraseSetRequest> | undefined): boolean {
    return proto3.util.equals(UpdatePhraseSetRequest, a, b);
  }
}

/**
 * Request message for the
 * [DeletePhraseSet][google.cloud.speech.v2.Speech.DeletePhraseSet] method.
 *
 * @generated from message google.cloud.speech.v2.DeletePhraseSetRequest
 */
export class DeletePhraseSetRequest extends Message<DeletePhraseSetRequest> {
  /**
   * Required. The name of the PhraseSet to delete.
   * Format: `projects/{project}/locations/{location}/phraseSets/{phrase_set}`
   *
   * @generated from field: string name = 1;
   */
  name = "";

  /**
   * If set, validate the request and preview the deleted PhraseSet, but do not
   * actually delete it.
   *
   * @generated from field: bool validate_only = 2;
   */
  validateOnly = false;

  /**
   * If set to true, and the PhraseSet is not found, the request will succeed
   * and  be a no-op (no Operation is recorded in this case).
   *
   * @generated from field: bool allow_missing = 4;
   */
  allowMissing = false;

  /**
   * This checksum is computed by the server based on the value of other
   * fields. This may be sent on update, undelete, and delete requests to ensure
   * the client has an up-to-date value before proceeding.
   *
   * @generated from field: string etag = 3;
   */
  etag = "";

  constructor(data?: PartialMessage<DeletePhraseSetRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.speech.v2.DeletePhraseSetRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "name", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "validate_only", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
    { no: 4, name: "allow_missing", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
    { no: 3, name: "etag", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): DeletePhraseSetRequest {
    return new DeletePhraseSetRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): DeletePhraseSetRequest {
    return new DeletePhraseSetRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): DeletePhraseSetRequest {
    return new DeletePhraseSetRequest().fromJsonString(jsonString, options);
  }

  static equals(a: DeletePhraseSetRequest | PlainMessage<DeletePhraseSetRequest> | undefined, b: DeletePhraseSetRequest | PlainMessage<DeletePhraseSetRequest> | undefined): boolean {
    return proto3.util.equals(DeletePhraseSetRequest, a, b);
  }
}

/**
 * Request message for the
 * [UndeletePhraseSet][google.cloud.speech.v2.Speech.UndeletePhraseSet]
 * method.
 *
 * @generated from message google.cloud.speech.v2.UndeletePhraseSetRequest
 */
export class UndeletePhraseSetRequest extends Message<UndeletePhraseSetRequest> {
  /**
   * Required. The name of the PhraseSet to undelete.
   * Format: `projects/{project}/locations/{location}/phraseSets/{phrase_set}`
   *
   * @generated from field: string name = 1;
   */
  name = "";

  /**
   * If set, validate the request and preview the undeleted PhraseSet, but do
   * not actually undelete it.
   *
   * @generated from field: bool validate_only = 3;
   */
  validateOnly = false;

  /**
   * This checksum is computed by the server based on the value of other
   * fields. This may be sent on update, undelete, and delete requests to ensure
   * the client has an up-to-date value before proceeding.
   *
   * @generated from field: string etag = 4;
   */
  etag = "";

  constructor(data?: PartialMessage<UndeletePhraseSetRequest>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "google.cloud.speech.v2.UndeletePhraseSetRequest";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "name", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 3, name: "validate_only", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
    { no: 4, name: "etag", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): UndeletePhraseSetRequest {
    return new UndeletePhraseSetRequest().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): UndeletePhraseSetRequest {
    return new UndeletePhraseSetRequest().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): UndeletePhraseSetRequest {
    return new UndeletePhraseSetRequest().fromJsonString(jsonString, options);
  }

  static equals(a: UndeletePhraseSetRequest | PlainMessage<UndeletePhraseSetRequest> | undefined, b: UndeletePhraseSetRequest | PlainMessage<UndeletePhraseSetRequest> | undefined): boolean {
    return proto3.util.equals(UndeletePhraseSetRequest, a, b);
  }
}

